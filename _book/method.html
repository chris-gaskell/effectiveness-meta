<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Method | The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis</title>
  <meta name="description" content="This document reports the results of a meta-analysis on naturalistic psychotherapy outcomes" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Method | The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document reports the results of a meta-analysis on naturalistic psychotherapy outcomes" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Method | The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis" />
  
  <meta name="twitter:description" content="This document reports the results of a meta-analysis on naturalistic psychotherapy outcomes" />
  

<meta name="author" content="Chris Gaskell" />


<meta name="date" content="2022-01-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="results.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Routine Psychotherapy Outcomes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html"><i class="fa fa-check"></i>Method</a>
<ul>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html#search-strategy-and-eligibility"><i class="fa fa-check"></i>Search Strategy and Eligibility</a></li>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html#extraction"><i class="fa fa-check"></i>Extraction</a>
<ul>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html#categorical-variables"><i class="fa fa-check"></i>Categorical variables</a></li>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html#continuous-variables"><i class="fa fa-check"></i>Continuous variables</a></li>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html#risk-of-bias-and-quality-assessment"><i class="fa fa-check"></i>Risk of Bias and Quality Assessment</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="method.html"><a href="method.html#analysis"><i class="fa fa-check"></i>Analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i>Results</a>
<ul>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#search-results"><i class="fa fa-check"></i>Search Results</a>
<ul>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#study-characteristics"><i class="fa fa-check"></i>Study Characteristics</a></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#sample-characteristics"><i class="fa fa-check"></i>Sample Characteristics</a></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#treatment-characteristics"><i class="fa fa-check"></i>Treatment Characteristics</a></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#risk-of-bias"><i class="fa fa-check"></i>Risk of Bias</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#meta-analyses"><i class="fa fa-check"></i>Meta-Analyses</a></li>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#moderator-analyses"><i class="fa fa-check"></i>Moderator Analyses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i>Discussion</a>
<ul>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html#interpretation-of-findings"><i class="fa fa-check"></i>Interpretation of Findings</a></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html#limitations"><i class="fa fa-check"></i>Limitations</a></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html#implications-for-research-policy-practice"><i class="fa fa-check"></i>Implications for Research, Policy &amp; Practice</a></li>
<li class="chapter" data-level="" data-path="discussion.html"><a href="discussion.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tables.html"><a href="tables.html"><i class="fa fa-check"></i>Tables</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#AppendixA"><i class="fa fa-check"></i>Appendix A. Systematic search terms</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-b.-preference-system-for-outcome-measures"><i class="fa fa-check"></i>Appendix B. Preference system for outcome measures</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-c.-systematic-review-screening-tool"><i class="fa fa-check"></i>Appendix C. Systematic review screening tool</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-d.-further-information-for-extraction-and-coding-process"><i class="fa fa-check"></i>Appendix D. Further information for extraction and coding process</a>
<ul>
<li class="chapter" data-level="0.0.1" data-path="appendix.html"><a href="appendix.html#sample-characteristics-1"><i class="fa fa-check"></i><b>0.0.1</b> Sample Characteristics</a></li>
<li class="chapter" data-level="0.0.2" data-path="appendix.html"><a href="appendix.html#methodological-information"><i class="fa fa-check"></i><b>0.0.2</b> Methodological Information</a></li>
<li class="chapter" data-level="0.0.3" data-path="appendix.html"><a href="appendix.html#service-information"><i class="fa fa-check"></i><b>0.0.3</b> Service Information</a></li>
<li class="chapter" data-level="0.0.4" data-path="appendix.html"><a href="appendix.html#treatment-information"><i class="fa fa-check"></i><b>0.0.4</b> Treatment Information</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-e.-quality-appraisal-tool"><i class="fa fa-check"></i>Appendix E. Quality appraisal tool</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-f.-supplementary-material-link"><i class="fa fa-check"></i>Appendix F. Supplementary material link</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#appendix-g.-systematic-search-exclusion-reasons"><i class="fa fa-check"></i>Appendix G. Systematic search exclusion reasons</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="method" class="section level1 unnumbered">
<h1>Method</h1>
<div id="search-strategy-and-eligibility" class="section level2 unnumbered">
<h2>Search Strategy and Eligibility</h2>
<p>A systematic review and meta-analysis were conducted and reported using the Preferred Reporting Items for Systematic Review and Meta-Analysis guidelines <span class="citation">(PRISMA, <a href="#ref-Page2021" role="doc-biblioref">Page et al., 2021</a>)</span> and the meta-analyses in psychotherapy <span class="citation">(MAP-24, <a href="#ref-Fluckiger2018" role="doc-biblioref">Flückiger et al., 2018</a>)</span> guidelines. The review protocol was pre-registered through PROSPERO (CRD42020175235).</p>
<p>Literature was searched for articles reported prior to the search date (-April 2020) using the following inclusion criteria: (a) treatment delivered in a service which offers routine treatment (i.e., not primarily for research); (b) all adult sample (no patients under 16); (c) employed a <em>psychological treatment</em> (i.e., driven by psychological theory and intended to be therapeutic <span class="citation">(<a href="#ref-Spielmans2018" role="doc-biblioref">Spielmans &amp; Flückiger, 2018</a>)</span>, as inferred or described by study manuscripts, family/group treatments were excluded); and (d) conducted face-to-face. Studies were then excluded if they: (e) were not available in English; (f) did not employ a self-report measure of treatment effectiveness (i.e. process, predictor, well-being or satisfaction measures not accepted); (g) did not provide an outcome for the acute treatment stage (i.e., pre-post comparison, or in the absence of post-treatment score the soonest available follow-up measurement to a maximum of 6-months); or (f) employed randomization procedures or control groups. Although randomised control trials seek to reduce internal bias, their conditions are often not typical of routine services as the need for patient consent will lead to bias in who is offered and who accepts these conditions, therefore reducing representativeness. For study PICO table see supplementary Table 1.</p>
<p>There were three phases to the systematic search. Phase one was a systematic search of three electronic literature databases (MEDLINE, CINAHL and PsycInfo) via EBSCO using a pre-developed list of key terms. Study titles/abstracts were required to have a methodologically <em>AND</em> psychologically relevant term. Methodological terms (indicating effectiveness research) included: <em>practice-based evidence</em>, <em>routine practice</em>, <em>benchmarking</em>, <em>transportability</em>, <em>transferability</em>, <em>clinically representative</em>, <em>managed care setting</em>, <em>uncontrolled</em>, <em>external validity</em>, <em>applicable findings</em>, <em>empirically supported</em>, <em>dissemination</em>, and <em>clinical effectiveness evaluation</em>. These terms were selected based on their use in prior reviews of psychotherapy effectiveness <span class="citation">(<a href="#ref-Cahill2010" role="doc-biblioref">Cahill et al., 2010</a>; <a href="#ref-Stewart2009a" role="doc-biblioref">Stewart &amp; Chambless, 2009</a>)</span>. <em>Effectiveness</em> and <em>evaluation</em> were not used as single word terms due to producing unmanageable numbers of hits. For the psychologically relevant term: *psycho** OR *therap** was used for PsycInfo while *psycho** alone was used for MEDLINE and CINAHL (*therap** was removed due to unmanageable number of irrelevant hits). Limiters included <em>adult population</em> and <em>English language</em>. No exclusions were made based on the type of publication. Key term combinations and Boolean operators are reported in supplementary Table 2. Phase two included (a) a manual search of reference lists, and (b) forward citation searching (using Google Scholar) for all studies identified in phase one. Article titles relevant to the current review were identified by the first author using the search terms. Finally, phase three was a pragmatic grey literature search using the terms <em>psychotherapy</em> AND <em>routine-practice</em> AND <em>effectiveness</em> in GoogleScholar before reviewing the first 50 pages of results. When contacting study authors for additional information an accompanying invitation to recommend additional studies was made.</p>
<p>After removal of duplicates search results were imported to <em>Rayyan</em> <span class="citation">(<a href="#ref-Ouzzani2016" role="doc-biblioref">Ouzzani et al., 2016</a>)</span>. Rayyan is a web-platform that supports title/abstract screening through blinding decision results among collaborators and sorting abstracts by probability of inclusion through text mining. Studies identified from the systematic search were screened by the first author using a pre-developed and piloted screening tool. A sub-sample were screened by a second coder at each stage. Percentage agreement and inter-rater reliability statistics <span class="citation">(Kappa [<span class="math inline">\(\kappa\)</span>], <a href="#ref-Cohen1960" role="doc-biblioref">Cohen, 1960</a>)</span> were used to quantify screening precision. Descriptive classifiers available for interpreting <span class="math inline">\(\kappa\)</span> were employed <span class="citation">(<a href="#ref-Landis1977" role="doc-biblioref">Landis &amp; Koch, 1977</a>)</span>, consisting of <em>slight</em> (0-0.2), <em>fair</em> (0.2-0.4), <em>moderate</em> (0.4-0.6), <em>substantial</em> (0.6-0.8), and <em>almost perfect</em> (0.8-1.0).
20% of titles/abstracts were coded by a trainee clinical psychologist showing substantial reliability
(<span class="math inline">\(\kappa\)</span> = 0.78,
1713/1740, 98.45%)
and 10% of full texts were coded by a clinical psychologist, showing strong reliability
(<span class="math inline">\(\kappa\)</span> = 0.65, 24/30, 80%).
For many included studies (212/252, 84.13%) authors were contacted via e-mail for additional information (two-week response time).
177 requests were for missing correlations while
35 were for additional data (e.g. M, SD etc.).
E-mail responses were received for 76 authors
(35.85%) while data was provided for 41 samples
(19.34%).</p>
</div>
<div id="extraction" class="section level2 unnumbered">
<h2>Extraction</h2>
<p>There was three separate outcome domains (and subsequently three meta-analyses) for <em>depression</em>, <em>anxiety</em> and <em>miscellaneous</em> outcomes.
For anxiety and depression, domain allocation was informed by the measure employed (i.e., depression measures in <em>depression</em>, anxiety measures in <em>anxiety</em>). All other effectiveness measures were placed in the <em>miscellaneous</em> domain; which commonly consisted of (i) general psychological distress scales, and then to a lesser extent (ii) peripheral outcomes scales indicating symptom amelioration (e.g., functioning, quality of life), or (iii) diagnosis-specific outcome scales (e.g., OCD, PTSD). Samples were not exclusive to disorder specific populations/treatments and therefore domains should not be seen as synonymous with diagnosis/treatment.</p>
<p>A standardised extraction sheet was developed and pilot-tested with a sample of studies (<em>k</em> = 10). When extracting, pooled study samples were preferred. When only multiple independent samples were reported then effect-sizes were aggregated prior to meta-analysis to reduce bias of statistical dependency <span class="citation">(<a href="#ref-Gleser2009" role="doc-biblioref">Gleser &amp; Olkin, 2009</a>; <a href="#ref-Hoyt2018" role="doc-biblioref">Hoyt &amp; Del Re, 2018</a>)</span>. To avoid loss of information, study samples were disaggregated for moderator analyses <span class="citation">(<a href="#ref-Cooper1998" role="doc-biblioref">Cooper, 1998</a>)</span>. Studies with overlapping datasets were excluded. Samples which analysed patients lost to follow up were preferred to completer samples as they are less prone to attrition bias <span class="citation">(<a href="#ref-Juni2001" role="doc-biblioref">Jüni et al., 2001</a>)</span>.
As extraction of multiple study effect-sizes within a single domain would lead to to statistical dependency <span class="citation">(<a href="#ref-Borenstein2021" role="doc-biblioref">Borenstein et al., 2021</a>)</span> we selected a single effect-size per sample, per domain <span class="citation">(<a href="#ref-Card2015" role="doc-biblioref">Card, 2015</a>; <a href="#ref-Cuijpers2016" role="doc-biblioref">P. Cuijpers, 2016</a>)</span>, using a preference system (defined a priori, supplementary material) favouring most commonly employed measures in routine practice. As the current review only included self-report measures the need to select among multiple measures was rarely required.
Reliability of coding for effect-size data was computed using a second coder for a sub-sample of manuscripts (n = 29) demonstrating almost perfect reliability
across all values (
<span class="math inline">\(\kappa\)</span> = 0.97, agreement = 97.56%)
and perfect reliability for effect-size values (<span class="math inline">\(\kappa\)</span> = 1.00). Key categorical and numerical variables extracted from manuscripts for moderator analyses are reported in table X.</p>
<div style="page-break-after: always;"></div>
<p><em>[[[——— ——— ——— ——— Insert Table 1 here ——— ——— ——— ———]]]</em></p>
<div id="categorical-variables" class="section level3 unnumbered">
<h3>Categorical variables</h3>
<ul>
<li><strong>Setting:</strong> the study was (i) <em>out-patient</em>, (ii) <em>inpatient</em> or (iii) <em>mixed.</em></li>
<li><strong>Analysis method:</strong> samples (i) <em>included</em> or (ii) <em>excluded</em> (completers) patients lost to follow up.</li>
<li><strong>Severity:</strong> was determined through a stratification of studies based on characteristics of the service <span class="citation">(similar <a href="#ref-deJong2021a" role="doc-biblioref">de Jong et al., 2021</a>)</span>. (i) <em>Mild services</em> included primary care, physical health, University counselling, voluntary, private and employee assistance programmes; (ii) <em>Moderate services</em> included secondary care, community mental health centres, specialist psychotherapy centres, managed care settings, or intensive outpatient programmes; (iii) <em>severe services</em> represented inpatient samples; and (iv) <em>university</em> included university out-patient and training clinics.</li>
<li><strong>Treatment modality:</strong> Treatments were coded as (i) <em>cognitive-behavioral</em> or (ii) <em>psychodynamic</em> based on manuscript self-designation (i.e., if the manuscript described treatment as CBT, then that was coded). In the absence of these terms then modality of best-fit were decided based on available treatment descriptions. Treatments that could not be confidently allocated to these groups were coded as (iii) <em>counselling</em> (e.g., person-centred, unspecific) or (iv) <em>other</em>. Treatments that did not describe treatment modality were rated as other.</li>
<li><strong>Continent:</strong> Studies were coded as North America, United Kingdom (UK), mainland Europe, Australasia, or Asia. The UK was separated from Europe because of the high representation of outcomes research coming from the UK.</li>
<li><strong>Intervention development stage:</strong> Studies were coded as (i) <em>preliminary studies</em> (i.e., testing novel treatments or treatment iterations) or (ii) <em>routine evaluations</em>.</li>
<li><strong>Experience:</strong> Samples for which treatment delivery was exclusively by training professionals were coded as (i) <em>trainees</em> while studies with no evidence of training professionals were coded as (ii) <em>qualified</em></li>
<li><strong>Measurement tool:</strong> Measures that were represented at least ten times in the meta-analysis were entered as subgroups.</li>
<li><strong>Sample Size:</strong> Following the approach of <span class="citation"><a href="#ref-Barth2013a" role="doc-biblioref">Barth et al.</a> (<a href="#ref-Barth2013a" role="doc-biblioref">2013</a>)</span>, studies were coded as small (N=&lt;25), medium (N=25-50), or large (N=50+).</li>
</ul>
</div>
<div id="continuous-variables" class="section level3 unnumbered">
<h3>Continuous variables</h3>
<ul>
<li><strong>Age:</strong> Sample mean average age.</li>
<li><strong>Dosage:</strong> Sample mean average treatment sessions.</li>
<li><strong>Year:</strong> of publication.</li>
<li><strong>Female preponderance</strong>: Sample rate (%).</li>
<li><strong>Married</strong>: Sample rate (%).</li>
<li><strong>Employed</strong>: Sample rate (%).</li>
<li><strong>Ethnic minority</strong>: Sample rate (%).</li>
</ul>
<div style="page-break-after: always;"></div>
</div>
<div id="risk-of-bias-and-quality-assessment" class="section level3 unnumbered">
<h3>Risk of Bias and Quality Assessment</h3>
<p>The Joanna Briggs Institute Quality Appraisal Tool for Case Series <span class="citation">(<a href="#ref-Munn2020" role="doc-biblioref">Munn et al., 2020</a>)</span> was used to rate study risk of bias. Eight criteria primarily focusing upon manuscript reporting detail were used. Criteria included manuscript reporting of: (i) service inclusion criteria, (ii) service description, (iii) treatment description, (iv) sample characteristics, (v) outcome data, (vi) effect-size calculation, (vii) consecutive patient recruitment, and (viii) inclusion of patients lost to follow-up (in statistical analysis). Each item was coded as either met or not met (including not clear) by the first author for each sample. A sub-sample (23.8%) was second coded by a pair of MSc psychological research methods students (11.9% each).</p>
<p>The methodological quality for the body of evidence within each meta-analytic domain was assessed by three reviewers using guidelines for the Grading of Recommendations, Assessment, Development and Evaluations <span class="citation">(GRADE, <a href="#ref-Guyatt2008" role="doc-biblioref">Guyatt et al., 2008</a>)</span>. This framework rates evidence quality for each meta-analytic outcome based on included study designs. Individual ratings are initially provided (high, moderate, low or very low) and are then down-graded (or upgraded) through evaluation of five separate criteria; risk of bias within included studies, inconsistencies in aggregated treatment effect, indirectness of evidence, imprecision and publication bias.</p>
</div>
</div>
<div id="analysis" class="section level2 unnumbered">
<h2>Analysis</h2>
<p>All analyses were conducted using the R statistical analysis environment <span class="citation">(<a href="#ref-R-base" role="doc-biblioref">R Core Team, 2020</a>, v 4.0.2)</span>. Reporting of effect-size calculation followed available guidance <span class="citation">(<a href="#ref-Hoyt2018" role="doc-biblioref">Hoyt &amp; Del Re, 2018</a>)</span>. We calculated the standardised mean change <span class="citation">(SMC: <a href="#ref-Becker1988" role="doc-biblioref">Becker, 1988</a>)</span> for included studies using the <em>metafor</em> package. This approach divides the pre-post mean change score by the pretreatment standard deviation.
Calculation of the sampling variance required an estimate of the pre-post correlation <span class="citation">(<a href="#ref-Morris2008" role="doc-biblioref">Morris, 2008</a>)</span>. For manuscripts not reporting all required information an approach to obtaining and/or imputing was followed (designed a priori, supplementary Table 3). When unavailable, Pearson’s <em>r</em> was imputed using an empirically derived estimate <span class="citation">(<em>r</em> = .60, <a href="#ref-Balk2012" role="doc-biblioref">Balk et al., 2012</a>)</span>. If all steps of this approach were unsuccessful then the study was removed from the meta-analysis. Aggregation of study samples (or sampling errors) was conducted using the <em>aggregate</em> function of <em>metafor</em> using standard inverse-variance weighting.</p>
<p>Meta-analyses were performed using the <em>metafor</em> <span class="citation">(<a href="#ref-R-metafor" role="doc-biblioref">Viechtbauer, 2020</a>)</span>, <em>dmetar</em> <span class="citation">(<a href="#ref-Harrer2019a" role="doc-biblioref">Harrer et al., 2019a</a>)</span>, and <em>meta</em> <span class="citation">(<a href="#ref-R-meta" role="doc-biblioref">Schwarzer, 2020</a>)</span> packages.
Due to expected high heterogeneity, random-effects meta-analyses were used to estimate pooled and weighted effect-sizes <span class="citation">(<a href="#ref-Higgins2008" role="doc-biblioref">Higgins &amp; Green, 2008</a>)</span>. This approach holds the assumption that included studies are randomly sampled from a population of studies <span class="citation">(<a href="#ref-Borenstein2021" role="doc-biblioref">Borenstein et al., 2021</a>)</span>.
95% confidence intervals were calculated for included studies.
Forest plots were used to visualise the pattern of effects however due to the high number of studies they were stripped of text. As the large differences in study N risked disproportionate weighting of small samples <span class="citation">(<a href="#ref-Borenstein2021" role="doc-biblioref">Borenstein et al., 2021</a>)</span> a post-hoc sensitivity analysis was performed through re-running the primary meta-analyses using fixed-effects models.
Between-study heterogeneity was assessed using I<sup>2</sup> <span class="citation">(<a href="#ref-Higgins2002" role="doc-biblioref">Higgins &amp; Thompson, 2002</a>)</span> and the Q statistic <span class="citation">(<a href="#ref-Cochran1954" role="doc-biblioref">Cochran, 1954</a>)</span>. I<sup>2</sup> was interpreted as <em>low</em> (25-50%), <em>moderate</em> (50-75%) or <em>high</em> <span class="citation">(75-100%, <a href="#ref-Higgins2003" role="doc-biblioref">Higgins et al., 2003</a>)</span>. The impact of publication bias on treatment estimates was visualised using funnel plots and assessed statistically using rank correlation tests <span class="citation">(<a href="#ref-Begg1994" role="doc-biblioref">Begg &amp; Mazumdar, 1994</a>)</span>, Egger’s regression test for funnel plot asymmetry <span class="citation">(<a href="#ref-Egger1997" role="doc-biblioref">Egger et al., 1997</a>)</span>, and fail-safe N <span class="citation">(Rosenthal method, <a href="#ref-Rosenthal1979" role="doc-biblioref">Rosenthal, 1979</a>)</span>.</p>
<p>Heterogeneity of SMC scores were tested using a range of pre-defined continuous (i.e., meta-regression) and categorical (i.e., subgroup analysis) moderator variables. Subgroup variables included:
(i) <em>setting</em> (inpatient vs outpatient),
(ii) <em>analysis</em> (i.e., non-/inclusion of patients lost to follow-up),
(iv) <em>continent</em>,
(iii) <em>severity</em> (mild, moderate, severe, university)
(v) <em>treatment modality</em>,
(vi) <em>experience</em> (unqualified vs. qualified therapists)
(vii) <em>stage of treatment development</em> (preliminary study vs. routine evaluations),
(viii) <em>measurement tool</em>, and
(ix) <em>sample size</em> (small, medium, large).
Meta-regression variables included
(i) <em>publication year</em>,
(ii) average <em>age</em> of sample,
(iii) <em>dosage</em> (i.e. outpatient treatment sessions), and sample characteristics (% of samples: <em>female</em>, <em>minority ethnicity</em>, <em>married</em>, and in full-time <em>employment</em>.
Moderator analyses followed available guidance <span class="citation">(<a href="#ref-Harrer2019" role="doc-biblioref">Harrer et al., 2019b</a>)</span>. Studies that were not relevant to a specific moderator analysis (or did not report required information) were temporarily omitted. All moderator analyses utilised mixed effect models <span class="citation">(<a href="#ref-Borenstein2021" role="doc-biblioref">Borenstein et al., 2021</a>)</span> with weighted estimation (inverse-variance weights). This approach uses random effects models for subgroup pooled effect sizes and fixed-effect models for testing differences between subgroups. An omnibus test (QM-test) was used to assess for significant subgroup differences (<em>p</em> = &lt; .05). Significant moderators were considered through inspection of 95% confidence intervals nonoverlap.</p>
<p>Multivariate meta regression was used to assess two models specified a priori. These included (i) <em>analysis</em>x<em>dosage</em>, and (ii) <em>continent</em>x<em>dosage</em>. Models were first developed using the subgroup (i.e., dummy) variable only, then with inclusion of dosage, and finally allowing for interactions. Significant models (<em>p</em> = &lt;.05) were compared for goodness-of-fit using log-likelihood score, and Akaike’s-information criteria (AIC).</p>

<div style="page-break-after: always;"></div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Balk2012" class="csl-entry">
Balk, E. M., Earley, A., Patel, K., Trikalinos, T. A., &amp; Dahabreh, I. J. (2012). Empirical assessment of within-arm correlation imputation in trials of continuous outcomes. <em>Methods Research Reports</em>, <em>12</em>(13).
</div>
<div id="ref-Barth2013a" class="csl-entry">
Barth, J., Munder, T., Gerger, H., Nüesch, E., Trelle, S., Znoj, H., Jüni, P., &amp; Cuijpers, P. (2013). Comparative efficacy of seven psychotherapeutic interventions for patients with depression: A network meta-analysis. <em>PLoS Medicine</em>, <em>10</em>(5), e1001454. <a href="https://doi.org/10.1371/journal.pmed.1001454">https://doi.org/10.1371/journal.pmed.1001454</a>
</div>
<div id="ref-Becker1988" class="csl-entry">
Becker, B. J. (1988). Synthesizing standardized mean-change measures. <em>British Journal of Mathematical &amp; Statistical Psychology</em>, <em>41</em>(2), 257–278. <a href="https://doi.org/10.1111/j.2044-8317.1988.tb00901">https://doi.org/10.1111/j.2044-8317.1988.tb00901</a>
</div>
<div id="ref-Begg1994" class="csl-entry">
Begg, C. B., &amp; Mazumdar, M. (1994). Operating characteristics of a rank correlation test for publication bias. <em>Biometrics</em>, <em>50</em>(4), 1088–1101. <a href="https://doi.org/10.2307/2533446">https://doi.org/10.2307/2533446</a>
</div>
<div id="ref-Borenstein2021" class="csl-entry">
Borenstein, M., Hedges, L. V., Higgins, J. P. T., &amp; Rothstein, H. R. (2021). <em>Introduction to <span>Meta-Analysis</span></em>. <span>John Wiley &amp; Sons</span>.
</div>
<div id="ref-Cahill2010" class="csl-entry">
Cahill, J., Barkham, M., &amp; Stiles, W. (2010). Systematic review of practice-based research on psychological therapies in routine clinic settings. <em>The British Journal of Clinical Psychology</em>, <em>49</em>(4), 421–453. <a href="https://doi.org/10.1348/014466509X470789">https://doi.org/10.1348/014466509X470789</a>
</div>
<div id="ref-Card2015" class="csl-entry">
Card, N. A. (2015). <em>Applied <span>Meta-Analysis</span> for <span>Social Science Research</span></em>. <span>Guilford Publications</span>.
</div>
<div id="ref-Cochran1954" class="csl-entry">
Cochran, W. G. (1954). The combination of estimates from different experiments. <em>Biometrics</em>, <em>10</em>(1), 101–129. <a href="https://doi.org/10.2307/3001666">https://doi.org/10.2307/3001666</a>
</div>
<div id="ref-Cohen1960" class="csl-entry">
Cohen, J. (1960). A coefficient of agreement for nominal scales. <em>Educational and Psychological Measurement</em>, <em>20</em>(1), 37–46. <a href="https://doi.org/10.1177/001316446002000104">https://doi.org/10.1177/001316446002000104</a>
</div>
<div id="ref-Cooper1998" class="csl-entry">
Cooper, H. M. (1998). <em>Synthesizing <span>Research</span>: <span>A Guide</span> for <span>Literature Reviews</span></em>. <span>SAGE</span>.
</div>
<div id="ref-Cuijpers2016" class="csl-entry">
Cuijpers, P. (2016). <em>Meta-analyses in mental health research: <span>A</span> practical guide</em>. <span>University of Amsterdam</span>.
</div>
<div id="ref-deJong2021a" class="csl-entry">
de Jong, K., Conijn, J. M., Gallagher, R. A. V., Reshetnikova, A. S., Heij, M., &amp; Lutz, M. C. (2021). Using progress feedback to improve outcomes and reduce drop-out, treatment duration, and deterioration: <span>A</span> multilevel meta-analysis. <em>Clinical Psychology Review</em>, <em>85</em>, 102002. <a href="https://doi.org/10.1016/j.cpr.2021.102002">https://doi.org/10.1016/j.cpr.2021.102002</a>
</div>
<div id="ref-Egger1997" class="csl-entry">
Egger, M., Smith, G. D., Schneider, M., &amp; Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. <em>BMJ</em>, <em>315</em>(7109), 629–634. <a href="https://doi.org/10.1136/bmj.315.7109.629">https://doi.org/10.1136/bmj.315.7109.629</a>
</div>
<div id="ref-Fluckiger2018" class="csl-entry">
Flückiger, C., Del Re, A. C., Barth, J., Hoyt, W. T., Levitt, H., Munder, T., Spielmans, G. I., Swift, J. K., Vîslă, A., &amp; Wampold, B. E. (2018). Considerations of how to conduct meta-analyses in psychological interventions. <em>Psychotherapy Research</em>, <em>28</em>(3), 329–332. <a href="https://doi.org/10.1080/10503307.2018.1430390">https://doi.org/10.1080/10503307.2018.1430390</a>
</div>
<div id="ref-Gleser2009" class="csl-entry">
Gleser, L. J., &amp; Olkin, I. (2009). Stochastically dependent effect sizes. In H. Cooper, L. V. Hedges, &amp; J. C. Valentine (Eds.), <em>The <span>Handbook</span> of <span>Research Synthesis</span> and <span>Meta-Analysis</span></em> (Second, pp. 357–376). <span>Russell Sage</span>.
</div>
<div id="ref-Guyatt2008" class="csl-entry">
Guyatt, G. H., Oxman, A. D., Vist, G. E., Kunz, R., Falck-Ytter, Y., Alonso-Coello, P., &amp; Schünemann, H. J. (2008). <span>GRADE</span>: An emerging consensus on rating quality of evidence and strength of recommendations. <em>BMJ</em>, <em>336</em>(7650), 924–926. <a href="https://doi.org/10.1136/bmj.39489.470347.AD">https://doi.org/10.1136/bmj.39489.470347.AD</a>
</div>
<div id="ref-Harrer2019a" class="csl-entry">
Harrer, M., Cuijpers, P., Furukawa, T. A., &amp; Ebert, David. D. (2019a). <em>Dmetar: <span>Companion R</span> package for the guide ’doing meta-analysis in <span>R</span>’.</em> [R Package].
</div>
<div id="ref-Harrer2019" class="csl-entry">
Harrer, M., Cuijpers, P., Furukawa, Toshi. A., &amp; Ebert, David. D. (2019b). Multiple <span>Meta-Regression</span>. In <em>Doing meta-analysis in <span>R</span>: <span>A</span> hands-on guide</em>.
</div>
<div id="ref-Higgins2008" class="csl-entry">
Higgins, J., &amp; Green, S. (Eds.). (2008). <em>Cochrane <span>Handbook</span> for <span>Systematic Reviews</span> of <span>Interventions</span></em>. <span>John Wiley &amp; Sons, Ltd</span>. <a href="https://doi.org/10.1002/9780470712184.fmatter">https://doi.org/10.1002/9780470712184.fmatter</a>
</div>
<div id="ref-Higgins2002" class="csl-entry">
Higgins, J., &amp; Thompson, S. (2002). Quantifying heterogeneity in a meta-analysis. <em>Statistics in Medicine</em>, <em>21</em>(11), 1539–1558. <a href="https://doi.org/10.1002/sim.1186">https://doi.org/10.1002/sim.1186</a>
</div>
<div id="ref-Higgins2003" class="csl-entry">
Higgins, J., Thompson, S., Deeks, J. J., &amp; Altman, D. G. (2003). Measuring inconsistency in meta-analyses. <em>BMJ</em>, <em>327</em>(7414), 557–560. <a href="https://doi.org/10.1136/bmj.327.7414.557">https://doi.org/10.1136/bmj.327.7414.557</a>
</div>
<div id="ref-Hoyt2018" class="csl-entry">
Hoyt, W. T., &amp; Del Re, A. C. (2018). Effect size calculation in meta-analyses of psychotherapy outcome research. <em>Psychotherapy Research</em>, <em>28</em>(3), 379–388. <a href="https://doi.org/10.1080/10503307.2017.1405171">https://doi.org/10.1080/10503307.2017.1405171</a>
</div>
<div id="ref-Juni2001" class="csl-entry">
Jüni, P., Altman, D. G., &amp; Egger, M. (2001). Assessing the quality of controlled clinical trials. <em>BMJ</em>, <em>323</em>(7303), 42–46.
</div>
<div id="ref-Landis1977" class="csl-entry">
Landis, J. R., &amp; Koch, G. G. (1977). The measurement of observer agreement for categorical data. <em>Biometrics</em>, <em>33</em>(1), 159–174. <a href="https://doi.org/10.2307/2529310">https://doi.org/10.2307/2529310</a>
</div>
<div id="ref-Morris2008" class="csl-entry">
Morris, S. B. (2008). Estimating effect sizes from pretest-posttest-control group designs. <em>Organizational Research Methods</em>, <em>11</em>(2), 364–386. <a href="https://doi.org/10.1177/1094428106291059">https://doi.org/10.1177/1094428106291059</a>
</div>
<div id="ref-Munn2020" class="csl-entry">
Munn, Z., Barker, T. H., Moola, S., Tufanaru, C., Stern, C., McArthur, A., Stephenson, M., &amp; Aromataris, E. (2020). Methodological quality of case series studies: An introduction to the <span>JBI</span> critical appraisal tool. <em>JBI Evidence Synthesis</em>, <em>18</em>(10), 2127–2133. <a href="https://doi.org/10.11124/JBISRIR-D-19-00099">https://doi.org/10.11124/JBISRIR-D-19-00099</a>
</div>
<div id="ref-Ouzzani2016" class="csl-entry">
Ouzzani, M., Hammady, H., Fedorowicz, Z., &amp; Elmagarmid, A. (2016). Rayyan: A web and mobile app for systematic reviews. <em>Systematic Reviews</em>, <em>5</em>(1), 210. <a href="https://doi.org/10.1186/s13643-016-0384-4">https://doi.org/10.1186/s13643-016-0384-4</a>
</div>
<div id="ref-Page2021" class="csl-entry">
Page, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., Shamseer, L., Tetzlaff, J. M., Akl, E. A., Brennan, S. E., Chou, R., Glanville, J., Grimshaw, J. M., Hróbjartsson, A., Lalu, M. M., Li, T., Loder, E. W., Mayo-Wilson, E., McDonald, S., … Moher, D. (2021). The <span>PRISMA</span> 2020 statement: <span>An</span> updated guideline for reporting systematic reviews. <em>PLOS Medicine</em>, <em>18</em>(3), e1003583. <a href="https://doi.org/10.1371/journal.pmed.1003583">https://doi.org/10.1371/journal.pmed.1003583</a>
</div>
<div id="ref-R-base" class="csl-entry">
R Core Team. (2020). <em>R: A language and environment for statistical computing</em>. R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>
</div>
<div id="ref-Rosenthal1979" class="csl-entry">
Rosenthal, R. (1979). The file drawer problem and tolerance for null results. <em>Psychological Bulletin</em>, <em>86</em>(3), 638–641. <a href="https://doi.org/10.1037/0033-2909.86.3.638">https://doi.org/10.1037/0033-2909.86.3.638</a>
</div>
<div id="ref-R-meta" class="csl-entry">
Schwarzer, G. (2020). <em>Meta: General package for meta-analysis</em>. <a href="https://CRAN.R-project.org/package=meta">https://CRAN.R-project.org/package=meta</a>
</div>
<div id="ref-Spielmans2018" class="csl-entry">
Spielmans, G. I., &amp; Flückiger, C. (2018). Moderators in psychotherapy meta-analysis. <em>Psychotherapy Research</em>, <em>28</em>(3), 333–346. <a href="https://doi.org/10.1080/10503307.2017.1422214">https://doi.org/10.1080/10503307.2017.1422214</a>
</div>
<div id="ref-Stewart2009a" class="csl-entry">
Stewart, R. E., &amp; Chambless, D. L. (2009). Cognitive-behavioral therapy for adult anxiety disorders in clinical practice: <span>A</span> meta-analysis of effectiveness studies. <em>Journal of Consulting and Clinical Psychology</em>, <em>77</em>(4), 595–606. <a href="https://doi.org/10.1037/a0016032">https://doi.org/10.1037/a0016032</a>
</div>
<div id="ref-R-metafor" class="csl-entry">
Viechtbauer, W. (2020). <em>Metafor: Meta-analysis package for r</em>. <a href="https://CRAN.R-project.org/package=metafor">https://CRAN.R-project.org/package=metafor</a>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-methods.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
