[["index.html", "The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis Abstract", " The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis Chris Gaskell 2022-01-01 Abstract Objective: Most psychotherapy is delivered in naturalistic settings. There has been a substantial increase in recent decades in the amount of evidence generated by routine services and so this review sought to examine the effectiveness of routinely delivered psychological therapies. Method: A pre-registered systematic-review and random-effects meta-analysis on studies meeting pre-specified inclusion criteria was conducted (CRD42020175235). Between-study heterogeneity was explored using methodological and clinical variables in univariate and multivariate moderator analyses. Results: The systematic search identified 252 studies (k = 298 samples), of which 223 (k = 263 samples) were eligible for inclusion in the meta-analysis. Results showed large effects for depression (d = 0.96, [CI 0.88-1.04], p = &lt; 0.001, k = 122), anxiety (d = 0.8 [CI 0.71-0.9], p = &lt; 0.001, k = 69), and miscellaneous outcomes (d = 1.01 [CI 0.93-1.09], p = &lt; 0.001, k = 158). Continent was the only significant moderator of treatment effects across all outcome domains. Conclusion: This review provides support for the effectiveness of routinely delivered psychological therapy. Findings should be interpreted with caution due to the observational nature of effectiveness studies and also the marked heterogeneity shown across study designs and characteristics. Keywords: ‘Psychotherapy,’ ‘Effectiveness,’ ‘Naturalistic,’ ‘Routine Outcomes,’ ‘Meta-analysis.’ Clinical Significance of this Article: The present study is the most comprehensive systematic review and meta-analysis of outcome data from practice-based psychotherapy studies. Pooling data from various countries, clinical contexts, therapy modalities and outcome measures, this study provides robust evidence that routinely delivered psychological interventions are effective for the treatment of depression, anxiety and global psychological distress, with large effect sizes across these domains (d &gt; .80). Psychological treatments delivered in naturalistic settings are broadly effective for the alleviation of common indicators of psychological distress. "],["the-effectiveness-of-psychotherapy-delivered-in-routine-care-settings-a-systematic-review-and-meta-analysis.html", "The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis", " The Effectiveness of Psychotherapy Delivered in Routine Care Settings: A Systematic Review and Meta-Analysis "],["introduction.html", "Introduction", " Introduction Meta-analyses of clinical trials support the efficacy of psychotherapy for common mental health problems such as depression (P. Cuijpers et al., 2008), anxiety disorders (e.g., P. Cuijpers, Sijbrandij, et al., 2014; Mayo-Wilson et al., 2014; Olatunji et al., 2014; Sánchez-Meca et al., 2010; Wolitzky-Taylor et al., 2008), post-traumatic stress disorder (Lewis et al., 2020), obsessive-compulsive disorder (Rosa-Alcázar et al., 2008), eating disorders (Linardon et al., 2017), psychosis (Turner et al., 2020) and other conditions. Grounded in this evidence, clinical guidelines endorse the use of psychological interventions in routine clinical care and support their inclusion in organized health care systems (e.g., Chambless &amp; Hollon, 1998; Chambless &amp; Ollendick, 2001; 2011). These guidelines typically advocate the implementation of evidence-based models of psychotherapy, closely following the procedures implemented in clinical trials and specified in treatment manuals. To this end, competency frameworks have been developed to support the dissemination of empirically supported treatments through clinical training programmes and clinical supervision (e.g., Lemma et al., 2008; Roth et al., 2009; Roth &amp; Pilling, 2008). Despite its convincing experimental evidence base, there are reasons to expect that the effects of psychotherapy delivered in routine care settings may differ from those observed in clinical trials. Surveys of practicing clinicians reveal that many hold negative attitudes towards protocol-driven therapy and subsequently do not follow treatment manuals (e.g., Addis &amp; Krasnow, 2000). Hence, the extent to which routinely delivered psychotherapy resembles trial-based empirically supported treatments is unclear (Freedland et al., 2011). It has also been argued that the strict selection criteria applied in clinical trials may result in unusually homogeneous samples that do not adequately reflect clinical populations that are typical of routine care settings (e.g., Lambert, 2013; Zimmerman et al., 2002). It has also been argued that using control conditions within practice-based psychotherapy poses ethical concerns (e.g., leaving severely distressed samples untreated) and therefore various patient subgroups are likely to be under represented (Nordmo et al., 2020; Philips &amp; Falkenström, 2021). Differences in the clinical profiles of patients included and excluded from psychotherapy trials have been demonstrated (e.g., van der Lem et al., 2012), some studies have nevertheless found similar clinical outcomes when comparing samples from efficacy trials and routine practice (Lutz et al., 2016; Persons et al., 1999). However, this adequate transportability and effectiveness of evidence-based interventions is unlikely to be a general rule across all routine care settings. For example, significant variability in clinical outcomes has been found between clinics that implemented protocol-driven and highly standardized interventions in England (Gyani et al., 2013). This variability may be partly explained by differences in clinical and demographic features of local populations (i.e., case-mix) and partly explained by implementation degrees of freedom: differences in how clinics manage treatment selection and treatment duration (Clark et al., 2018). For all of these reasons, it is plausible to assume that the effects of routinely delivered therapy may vary across settings and clinical populations, and may not necessarily conform to benchmarks from efficacy trials. Given the above sources of uncertainty and variability, psychotherapy researchers have taken interest in evaluating the effectiveness of routinely delivered psychotherapy. A tradition of practice-based evidence (PBE, Margison et al., 2000) has emerged in recent decades, with numerous studies that examine the effects of routine care psychological interventions in various settings. Narrative reviews of PBE generally confirm that moderate-to-large uncontrolled (pre-to-post treatment) effect sizes are observed in routine care settings, supporting the effectiveness of psychotherapy but also demonstrating considerable variability across patient samples, therapists and clinics (e.g., see Barkham et al., 2010; Castonguay et al., 2013, 2021). An inherent limitation of such narrative reviews is that they perform a selective rather than systematic and comprehensive synthesis of available data. Benchmarking studies that pool practice-based data across multiple clinics tend to report favourable pooled effects sizes, but also variability in effects across clinics (e.g., Barkham et al., 2001; Connell et al., 2007; Delgadillo et al., 2014; Gyani et al., 2013). Although these studies help to quantify the expected magnitude of treatment effects observed in ordinary clinical settings, most are nevertheless circumscribed to small sets of clinics or geographical areas, offering limited insights into possible sources of heterogeneity in treatment outcomes. As such, systematic reviews and meta-analyses may be most illuminating. Some meta-analytic investigations have reported that outcomes of clinic-based studies were not as favourable as those based in research settings (Weisz et al., 1995). Other meta-analyses suggest that there are no differences in treatment effects when comparing clinic-based and efficacy studies when case-mix differences are accounted for (e.g., Shadish et al., 1997, 2000); however, many of the included clinic-based studies applied stringent controls on the treatment procedures – making them more akin to lab-based studies. Later reviews have attempted to systematically identify available PBE studies and to derive generalizable information on the general effectiveness of psychotherapy in routine care. Hunsley &amp; Lee (2007) reviewed 35 studies and concluded that the completion and improvement rates observed in PBE studies were comparable to those from efficacy trials. Cahill et al. (2010) reviewed 31 studies, concluding that psychotherapy was most effective for the treatment of common mental disorders with a pooled uncontrolled effect size of d = 1.29. More recently, Wakefield et al. (2021) reviewed 60 studies, of which 47 were eligible for meta-analysis. They reported large uncontrolled effect sizes for depression (d = 0.87) and anxiety (d = 0.88), and a moderate effect on functional impairment (d = 0.55). Heterogeneous effects are commonly found in psychotherapy meta-analyses, and can, to some extent, be explained through potential moderator variables (Spielmans &amp; Flückiger, 2018). More recent PBE meta-analyses have started to provide insights into plausible methodological (e.g., completers analyses vs. inclusion of patients lost to follow-up) and clinical sources of heterogeneity in effectiveness (e.g., larger effects for common mental disorders, lower effects for patients with comorbidities and socioeconomic disadvantages, larger effects for lengthier interventions). Nevertheless, these meta-analyses are over a decade old (Cahill et al., 2010; Hunsley &amp; Lee, 2007) or limited to a specific primary care setting (Wakefield et al., 2021). Further research into the methodological and clinical sources of treatment heterogeneity is needed for a more complete understanding of underlying differences in how people respond to treatment (Spielmans &amp; Flückiger, 2018). Recent meta-analyses of efficacy trials have provided evidence for a range of potential moderators variables that are yet to be confirmed through meta-analysis of PBE. Methodological risk of bias criteria have often been associated with overestimates of treatment effect (for a review see Munder &amp; Barth, 2018). Barth et al. (2013) for example observed inflateded effect sizes for psychotherapy treatment studies of depression that: (i) lacked concealment of randomization, (ii) used non-blinded outcome assessors, and (iii) employed small samples. P. Cuijpers et al. (2010) also found that exclusion of patients lost to follow-up (i.e., completer samples) produced inflated effect-sizes over studies that included such patients (i.e., intention-to-treat); although Barth et al. (2013) found conflicting evidence. Various clinical factors have been considered for their potential to explain heterogeneity of psychotherapy treatment findings (see Spielmans &amp; Flückiger, 2018 for a review). For treatment modality (e.g., cognitive-behavioural, psychodynamic) recent meta-analyses of RCTs directly comparing different treatments have provided limited evidence that there are significant differences between treatments for depression (Barth et al., 2013; P. Cuijpers et al., 2008). Similar investigations in other conditions (e.g., generalised anxiety) have been restricted by the lack of evidence from direct comparison trials (P. Cuijpers, Sijbrandij, et al., 2014). Aggregation of evidence for specific treatment modalities from non-comparative studies, although observational and highly susceptible to confounds, can allows for indirect comparisons of treatments. Treatment dosage (or duration) is a clinically and economically relevant treatment variable however is often absent from psychotherapy meta-analytic reviews (Spielmans &amp; Flückiger, 2018). While there are various dosage prototypes available (see Flückiger et al., 2020) it is generally recommended that meta-analytic reviewers code it as a continuous variable (Spielmans &amp; Flückiger, 2018). Several recent meta-analyses have failed to demonstrate a significant differential effect for dosage in depression (e.g., Barth et al., 2013; P. Cuijpers et al., 2013), anxiety (e.g., Carpenter et al., 2018) and OCD (e.g., Olatunji et al., 2015); although there remain exceptions to this rule (e.g., Olatunji et al., 2014; Turner et al., 2020). Consideration of dosage within naturalistic settings is particularly relevant as the range of sessions is often treated more flexibly (Lambert, 2013) and varies between services and mental health systems (Flückiger et al., 2020). Sample severity (i.e., clinical complexity of the sample) has been widely considered to be negatively associated with treatment effect. This has received meta-analytic support through comparatively smaller aggregate effect-sizes shown in meta-analyses of severe depression (e.g., P. Cuijpers et al., 2010) and inpatient samples (P. Cuijpers et al., 2011). Differences between stratifications of depression severity have also been shown, with more severe samples showing smaller effect sizes (Whiston et al., 2019). Despite this, conflicting evidence has been reported through study level meta analyses of depression (P. Cuijpers, Turner, et al., 2014; Driessen et al., 2010), and health anxiety (Olatunji et al., 2014) and independent patient level meta-analyses of depression (Furukawa et al., 2017) and psychosis (Turner et al., 2020). Furukawa et al. (2017) for example found that patients receiving CBT can benefit across the spectrum of pre-treatment severity of depression. Varying levels of support have also been provided for differential rates of effectiveness based upon role of the outcome assessor (self-report vs clinician, P. Cuijpers, Sijbrandij, et al., 2014; P. Cuijpers et al., 2008), sensitivity of measurement tool (e.g., P. Cuijpers, Sijbrandij, et al., 2014), and country. The degree to which these moderator variables findings are consistent within naturalistic settings remains unclear. The considerable growth of the PBE literature in the last decade and implementation of empirically supported treatments across many settings warrants a comprehensive review and quantitative synthesis of the literature. This would enable us to gain a more precise understanding of [1] the magnitude of effect sizes across multiple outcome domains and [2] sources of heterogeneity. The aim of the present study was to systematically review available PBE studies using a meta-analytic synthesis of quantitative data and pre-specified moderator analyses informed by earlier studies. Note: The authors recognise that use of the term effectiveness may be somewhat misleading. The pre-post (uncontrolled) methodology which forms the body of evidence in this review is unable to disentangle treatments effects from other potential causes of change (e.g., regression to the mean, placebo). Observed change in symptoms may therefore not exclusively represent treatment effectiveness. We have opted to retain use of this term within the current review because it has frequently been employed in the extant literature (e.g., Lambert, 2013; Nordmo et al., 2020). References "],["method.html", "Method Search Strategy and Eligibility Extraction Analysis", " Method Search Strategy and Eligibility A systematic review and meta-analysis were conducted and reported using the Preferred Reporting Items for Systematic Review and Meta-Analysis guidelines (PRISMA, Page et al., 2021) and the meta-analyses in psychotherapy (MAP-24, Flückiger et al., 2018) guidelines. The review protocol was pre-registered through PROSPERO (CRD42020175235). Literature was searched for articles reported prior to the search date (-April 2020) using the following inclusion criteria: (a) treatment delivered in a service which offers routine treatment (i.e., not primarily for research); (b) all adult sample (no patients under 16); (c) employed a psychological treatment (i.e., driven by psychological theory and intended to be therapeutic (Spielmans &amp; Flückiger, 2018), as inferred or described by study manuscripts, family/group treatments were excluded); and (d) conducted face-to-face. Studies were then excluded if they: (e) were not available in English; (f) did not employ a self-report measure of treatment effectiveness (i.e. process, predictor, well-being or satisfaction measures not accepted); (g) did not provide an outcome for the acute treatment stage (i.e., pre-post comparison, or in the absence of post-treatment score the soonest available follow-up measurement to a maximum of 6-months); or (f) employed randomization procedures or control groups. Although randomised control trials seek to reduce internal bias, their conditions are often not typical of routine services as the need for patient consent will lead to bias in who is offered and who accepts these conditions, therefore reducing representativeness. For study PICO table see supplementary Table 1. There were three phases to the systematic search. Phase one was a systematic search of three electronic literature databases (MEDLINE, CINAHL and PsycInfo) via EBSCO using a pre-developed list of key terms. Study titles/abstracts were required to have a methodologically AND psychologically relevant term. Methodological terms (indicating effectiveness research) included: practice-based evidence, routine practice, benchmarking, transportability, transferability, clinically representative, managed care setting, uncontrolled, external validity, applicable findings, empirically supported, dissemination, and clinical effectiveness evaluation. These terms were selected based on their use in prior reviews of psychotherapy effectiveness (Cahill et al., 2010; Stewart &amp; Chambless, 2009). Effectiveness and evaluation were not used as single word terms due to producing unmanageable numbers of hits. For the psychologically relevant term: *psycho** OR *therap** was used for PsycInfo while *psycho** alone was used for MEDLINE and CINAHL (*therap** was removed due to unmanageable number of irrelevant hits). Limiters included adult population and English language. No exclusions were made based on the type of publication. Key term combinations and Boolean operators are reported in supplementary Table 2. Phase two included (a) a manual search of reference lists, and (b) forward citation searching (using Google Scholar) for all studies identified in phase one. Article titles relevant to the current review were identified by the first author using the search terms. Finally, phase three was a pragmatic grey literature search using the terms psychotherapy AND routine-practice AND effectiveness in GoogleScholar before reviewing the first 50 pages of results. When contacting study authors for additional information an accompanying invitation to recommend additional studies was made. After removal of duplicates search results were imported to Rayyan (Ouzzani et al., 2016). Rayyan is a web-platform that supports title/abstract screening through blinding decision results among collaborators and sorting abstracts by probability of inclusion through text mining. Studies identified from the systematic search were screened by the first author using a pre-developed and piloted screening tool. A sub-sample were screened by a second coder at each stage. Percentage agreement and inter-rater reliability statistics (Kappa [\\(\\kappa\\)], Cohen, 1960) were used to quantify screening precision. Descriptive classifiers available for interpreting \\(\\kappa\\) were employed (Landis &amp; Koch, 1977), consisting of slight (0-0.2), fair (0.2-0.4), moderate (0.4-0.6), substantial (0.6-0.8), and almost perfect (0.8-1.0). 20% of titles/abstracts were coded by a trainee clinical psychologist showing substantial reliability (\\(\\kappa\\) = 0.78, 1713/1740, 98.45%) and 10% of full texts were coded by a clinical psychologist, showing strong reliability (\\(\\kappa\\) = 0.65, 24/30, 80%). For many included studies (212/252, 84.13%) authors were contacted via e-mail for additional information (two-week response time). 177 requests were for missing correlations while 35 were for additional data (e.g. M, SD etc.). E-mail responses were received for 76 authors (35.85%) while data was provided for 41 samples (19.34%). Extraction There was three separate outcome domains (and subsequently three meta-analyses) for depression, anxiety and miscellaneous outcomes. For anxiety and depression, domain allocation was informed by the measure employed (i.e., depression measures in depression, anxiety measures in anxiety). All other effectiveness measures were placed in the miscellaneous domain; which commonly consisted of (i) general psychological distress scales, and then to a lesser extent (ii) peripheral outcomes scales indicating symptom amelioration (e.g., functioning, quality of life), or (iii) diagnosis-specific outcome scales (e.g., OCD, PTSD). Samples were not exclusive to disorder specific populations/treatments and therefore domains should not be seen as synonymous with diagnosis/treatment. A standardised extraction sheet was developed and pilot-tested with a sample of studies (k = 10). When extracting, pooled study samples were preferred. When only multiple independent samples were reported then effect-sizes were aggregated prior to meta-analysis to reduce bias of statistical dependency (Gleser &amp; Olkin, 2009; Hoyt &amp; Del Re, 2018). To avoid loss of information, study samples were disaggregated for moderator analyses (Cooper, 1998). Studies with overlapping datasets were excluded. Samples which analysed patients lost to follow up were preferred to completer samples as they are less prone to attrition bias (Jüni et al., 2001). As extraction of multiple study effect-sizes within a single domain would lead to to statistical dependency (Borenstein et al., 2021) we selected a single effect-size per sample, per domain (Card, 2015; P. Cuijpers, 2016), using a preference system (defined a priori, supplementary material) favouring most commonly employed measures in routine practice. As the current review only included self-report measures the need to select among multiple measures was rarely required. Reliability of coding for effect-size data was computed using a second coder for a sub-sample of manuscripts (n = 29) demonstrating almost perfect reliability across all values ( \\(\\kappa\\) = 0.97, agreement = 97.56%) and perfect reliability for effect-size values (\\(\\kappa\\) = 1.00). Key categorical and numerical variables extracted from manuscripts for moderator analyses are reported in table X. [[[——— ——— ——— ——— Insert Table 1 here ——— ——— ——— ———]]] Categorical variables Setting: the study was (i) out-patient, (ii) inpatient or (iii) mixed. Analysis method: samples (i) included or (ii) excluded (completers) patients lost to follow up. Severity: was determined through a stratification of studies based on characteristics of the service (similar de Jong et al., 2021). (i) Mild services included primary care, physical health, University counselling, voluntary, private and employee assistance programmes; (ii) Moderate services included secondary care, community mental health centres, specialist psychotherapy centres, managed care settings, or intensive outpatient programmes; (iii) severe services represented inpatient samples; and (iv) university included university out-patient and training clinics. Treatment modality: Treatments were coded as (i) cognitive-behavioral or (ii) psychodynamic based on manuscript self-designation (i.e., if the manuscript described treatment as CBT, then that was coded). In the absence of these terms then modality of best-fit were decided based on available treatment descriptions. Treatments that could not be confidently allocated to these groups were coded as (iii) counselling (e.g., person-centred, unspecific) or (iv) other. Treatments that did not describe treatment modality were rated as other. Continent: Studies were coded as North America, United Kingdom (UK), mainland Europe, Australasia, or Asia. The UK was separated from Europe because of the high representation of outcomes research coming from the UK. Intervention development stage: Studies were coded as (i) preliminary studies (i.e., testing novel treatments or treatment iterations) or (ii) routine evaluations. Experience: Samples for which treatment delivery was exclusively by training professionals were coded as (i) trainees while studies with no evidence of training professionals were coded as (ii) qualified Measurement tool: Measures that were represented at least ten times in the meta-analysis were entered as subgroups. Sample Size: Following the approach of Barth et al. (2013), studies were coded as small (N=&lt;25), medium (N=25-50), or large (N=50+). Continuous variables Age: Sample mean average age. Dosage: Sample mean average treatment sessions. Year: of publication. Female preponderance: Sample rate (%). Married: Sample rate (%). Employed: Sample rate (%). Ethnic minority: Sample rate (%). Risk of Bias and Quality Assessment The Joanna Briggs Institute Quality Appraisal Tool for Case Series (Munn et al., 2020) was used to rate study risk of bias. Eight criteria primarily focusing upon manuscript reporting detail were used. Criteria included manuscript reporting of: (i) service inclusion criteria, (ii) service description, (iii) treatment description, (iv) sample characteristics, (v) outcome data, (vi) effect-size calculation, (vii) consecutive patient recruitment, and (viii) inclusion of patients lost to follow-up (in statistical analysis). Each item was coded as either met or not met (including not clear) by the first author for each sample. A sub-sample (23.8%) was second coded by a pair of MSc psychological research methods students (11.9% each). The methodological quality for the body of evidence within each meta-analytic domain was assessed by three reviewers using guidelines for the Grading of Recommendations, Assessment, Development and Evaluations (GRADE, Guyatt et al., 2008). This framework rates evidence quality for each meta-analytic outcome based on included study designs. Individual ratings are initially provided (high, moderate, low or very low) and are then down-graded (or upgraded) through evaluation of five separate criteria; risk of bias within included studies, inconsistencies in aggregated treatment effect, indirectness of evidence, imprecision and publication bias. Analysis All analyses were conducted using the R statistical analysis environment (R Core Team, 2020, v 4.0.2). Reporting of effect-size calculation followed available guidance (Hoyt &amp; Del Re, 2018). We calculated the standardised mean change (SMC: Becker, 1988) for included studies using the metafor package. This approach divides the pre-post mean change score by the pretreatment standard deviation. Calculation of the sampling variance required an estimate of the pre-post correlation (Morris, 2008). For manuscripts not reporting all required information an approach to obtaining and/or imputing was followed (designed a priori, supplementary Table 3). When unavailable, Pearson’s r was imputed using an empirically derived estimate (r = .60, Balk et al., 2012). If all steps of this approach were unsuccessful then the study was removed from the meta-analysis. Aggregation of study samples (or sampling errors) was conducted using the aggregate function of metafor using standard inverse-variance weighting. Meta-analyses were performed using the metafor (Viechtbauer, 2020), dmetar (Harrer et al., 2019a), and meta (Schwarzer, 2020) packages. Due to expected high heterogeneity, random-effects meta-analyses were used to estimate pooled and weighted effect-sizes (Higgins &amp; Green, 2008). This approach holds the assumption that included studies are randomly sampled from a population of studies (Borenstein et al., 2021). 95% confidence intervals were calculated for included studies. Forest plots were used to visualise the pattern of effects however due to the high number of studies they were stripped of text. As the large differences in study N risked disproportionate weighting of small samples (Borenstein et al., 2021) a post-hoc sensitivity analysis was performed through re-running the primary meta-analyses using fixed-effects models. Between-study heterogeneity was assessed using I2 (Higgins &amp; Thompson, 2002) and the Q statistic (Cochran, 1954). I2 was interpreted as low (25-50%), moderate (50-75%) or high (75-100%, Higgins et al., 2003). The impact of publication bias on treatment estimates was visualised using funnel plots and assessed statistically using rank correlation tests (Begg &amp; Mazumdar, 1994), Egger’s regression test for funnel plot asymmetry (Egger et al., 1997), and fail-safe N (Rosenthal method, Rosenthal, 1979). Heterogeneity of SMC scores were tested using a range of pre-defined continuous (i.e., meta-regression) and categorical (i.e., subgroup analysis) moderator variables. Subgroup variables included: (i) setting (inpatient vs outpatient), (ii) analysis (i.e., non-/inclusion of patients lost to follow-up), (iv) continent, (iii) severity (mild, moderate, severe, university) (v) treatment modality, (vi) experience (unqualified vs. qualified therapists) (vii) stage of treatment development (preliminary study vs. routine evaluations), (viii) measurement tool, and (ix) sample size (small, medium, large). Meta-regression variables included (i) publication year, (ii) average age of sample, (iii) dosage (i.e. outpatient treatment sessions), and sample characteristics (% of samples: female, minority ethnicity, married, and in full-time employment. Moderator analyses followed available guidance (Harrer et al., 2019b). Studies that were not relevant to a specific moderator analysis (or did not report required information) were temporarily omitted. All moderator analyses utilised mixed effect models (Borenstein et al., 2021) with weighted estimation (inverse-variance weights). This approach uses random effects models for subgroup pooled effect sizes and fixed-effect models for testing differences between subgroups. An omnibus test (QM-test) was used to assess for significant subgroup differences (p = &lt; .05). Significant moderators were considered through inspection of 95% confidence intervals nonoverlap. Multivariate meta regression was used to assess two models specified a priori. These included (i) analysisxdosage, and (ii) continentxdosage. Models were first developed using the subgroup (i.e., dummy) variable only, then with inclusion of dosage, and finally allowing for interactions. Significant models (p = &lt;.05) were compared for goodness-of-fit using log-likelihood score, and Akaike’s-information criteria (AIC). References "],["results.html", "Results Search Results Meta-Analyses Moderator Analyses", " Results Search Results A PRISMA flow diagram (Page et al., 2021) is shown in Figure 1. 10,503 records were identified through the systematic search. Following title/abstract screening there was 619 studies remaining. 30 manuscripts were not available through the first author’s institution. E-mail requests to corresponding authors led to the retrieval of 8 further manuscripts. Articles with unavailable manuscripts (n = 22) were excluded from the review. Following full-text screening there were 252 manuscripts remaining (k = 298), of which 223 (k = 263) had sufficient information to be included in the meta-analysis. Summary statistics are provided in Table 2. [[[——— ——— ——— ——— Insert Figure 1 here ——— ——— ——— ———]]] [[[——— ——— ——— ——— Insert Table 2 here ——— ——— ——— ———]]] Study Characteristics Study publication ranged from 1984 to 2020 (median = 2013, k = 294 published ≥ 2000). 169 samples included patients lost to follow-up (k = 118 completers). There were 34 (11.41%) preliminary study samples and 264 (88.59%) routine practice evaluation samples. The USA was the most well represented country (k = 113), followed by England (k = 78), Germany (k = 24), Sweden (k = 12), and Canada (k = 10). These five most well-represented countries accounted for the majority of the included samples (k = 237). For continent, North America (k = 123) was the most well represented, followed by the UK (k = 96), mainland Europe (k = 63), Australasia (k = 10), and Asia (k = 6). Sample Characteristics Sample characteristics were reported for 291 samples, with a cumulative N of 233,140 (mean = 838.63, median = 81.5, range = 4 - 33,243, IQR = 224.5 ). The female preponderance was 61.88% (N = 144,273, k = 279) with 13 all female samples and 2 all male samples. The mean average sample age was 35.33 years (range = 19.00 - 60.50). Across studies which provided information, 23.00% of patients represented minority ethnic backgrounds (k = 127), 37.00% were married (k = 106), and 23.00% were in employment (k = 96). Treatment Characteristics Most samples used a cognitive-behavioral treatment modality (k = 152) while 50 used psychodynamic, and 25 used counselling (other = 71). For severity, 96 (32.21%) samples came from mild services, 92 (30.87%) from moderate services, 33 (11.07%) from severe services, and 68 (22.82%) from University services (other, k = 9, 3.02%). Treatment dosage, when reported (k = 256) was in hours/sessions (k = 225), months (k = 12) or days (k = 8). The pooled (non-weighted) average dosage (hours) was 16.30 sessions (median = 13.00, range = 1.00-139.30, IQR = 11.00). 62 samples reported that treatment was delivered exclusively by unqualified/trainee clinicians, while 100 samples reported having at least one unqualified/trainee clinician. Risk of Bias There was 60 studies rated across 8 criteria (i.e., 480 items). The pooled agreement was 84.17 (\\(\\kappa\\) = 0.62). Individual items varied in there levels of agreement (70.0%-98.3%). In order of most met criteria was demographic reporting detail (264/298, agreement = 98.33%, \\(\\kappa\\) = 0.88), service reporting detail (260/298, agreement = 85%, \\(\\kappa\\) = 0.31), study outcome reporting details (240/298, agreement = 83.33%, \\(\\kappa\\) = -0.03), intervention reporting detail (234/298, agreement = 85%, \\(\\kappa\\) = 0.32), service inclusion criteria (214/298, agreement = 90%, \\(\\kappa\\) = 0.64), appropriate use of analysis (214/298, agreement = 70%, \\(\\kappa\\) = 0.26), complete inclusion (i.e. consecutive recruitment and inclusion of those lost to follow-up, 41/298, agreement = 85%, \\(\\kappa\\) = 0.45), and consecutive inclusion (93/298, agreement = 76.67%, \\(\\kappa\\) = 0.51), Meta-Analyses [[[——— ——— ——— ——— Insert Figures 2 here ——— ——— ——— ———]]] Details for individual studies (characteristics, effect-size, measurement tools) are presented in tabular form and forest plots (supplementary tables 4-5, supplementary figures 1-3). During the GRADE methodological appraisal process, each of the meta-analysis were initially rated as ‘low,’ based on the predominant type of study design within the available evidence. Following review of the five GRADE areas these overall ratings were reduced in level to ‘very low’ based on study limitations and also inconsistency within the available evidence. [[[——— ——— ——— ——— Insert Table 6 here ——— ——— ——— ———]]] The random-effects meta-analysis for depression outcomes (k = 140, N = 68,077), across 10 unique measurement tools was significant (p = &lt; 0.001), indicative of a strong (d = 0.96, CI = 0.88-1.04) reduction in depression symptoms. There was significant study heterogeneity (I2 = 97.94%, Q[df = 121] = 2,677.37, p = &lt; 0.001). The funnel plot (Figure X) shows limited visual evidence of asymmetry. The funnel rank correlation test was not significant (\\(\\tau\\) = 0.061, p = 0.46) however the funnel regression test was significant (Z = 2.13, p = 0.033). The fail-safe N was 515,853. The random-effects meta-analysis for anxiety outcomes (k = 84, N = 26,689, measurement tools = 20) was significant (p = &lt; 0.001), indicative of a strong (d = 0.8, CI = 0.71-0.9) reduction in symptoms. There was significant heterogeneity across studies (I2 = 97.51%, Q[df = 68] = 1,328.96, p = &lt; 0.001). The funnel plot shows limited evidence of asymmetry. The funnel rank correlation test was not significant (\\(\\tau\\) = 0.009, p = 0.888). In contrast, the funnel regression test was significant (Z = 2.533, p = 0.011). The fail-safe N was 121,899 The random-effects meta-analysis for miscellaneous outcomes (i.e., global distress, functioning, diagnosis specific; k = 184, N = 126,734, measurement tools = 40) was significant (p = &lt; 0.001), indicative of a strong (d = 1.01, CI = 0.93-1.09) reduction in symptoms. There was evidence of significant study heterogeneity across the included studies (I2 = 99.06%, Q[df = 157] = 15,330.32, p = &lt; 0.001). The funnel plot shows a degree of asymmetry with clustering to the right of the mid-line. The funnel rank correlation test was significant (\\(\\tau\\) = 0.208, p = &lt;0.001). In contrast, the funnel regression test was not significant (Z = 3.697, p = &lt;0.001). The fail-safe N was 1,695,607. The post-hoc fixed effects model (i.e., sensitivity analysis) was highly comparable for miscellaneous outcomes (fixed: d = 1.02, CI = 1.01-1.02; random: d = 1.01, CI = 0.93-1.09). The discrepancy was larger for depression outcomes (fixed: d = 0.81, CI = 0.8-0.82; random: d = 0.96 CI = 0.88-1.04). and larger still for anxiety outcomes (fixed: d = 0.57, CI = 0.56-0.58; random: d = 0.8 CI 0.71-0.9). Moderator Analyses Moderator analysis results are shown in Tables 3:6. The results of the omnibus models (QM tests) indicate moderators with significant between level variation. Continent was significant for all three outcome domains, with UK and North American studies producing larger effect sizes than other continents. Type of analysis, sample size, and treatment develeopment stage produced no significant findings. For setting (i.e., inpatient vs. outpatient) the omnibus model for anxiety was significant. Outpatient samples [d = 0.89, CI = 0.78-0.99] outperformed inpatient samples [d = 0.58, CI = 0.31-0.85]); although with CI overlap. [[[——— ——— ——— ——— Insert Tables 3:6 here ——— ——— ——— ———]]] Omnibus models for modality, severity, experience and measurement tool were significant for the anxiety and miscellaneous domains (but not depression). Therapy modality demonstrated that counselling (d = 0.43, CI = 0.38-0.49) produced smaller improvements in anxiety outcomes, although with a very small number of studies (k = 2). For miscellaneous outcomes CBT produced larger effect-sizes (d = 1.18, CI = 1.05-1.32) although with a narrow degree of overlap with psychodynamic (d = 0.93, CI = 0.79-1.07) and counselling outcomes (d = 0.90, CI = 0.75-1.06). For severity, anxiety outcomes were larger for mild (d = 0.99, CI = 0.79-1.20) and university services (d = 1.01, CI = 0.83-1.20) than for severe or moderate services. For miscellaneous outcomes, effect sizes were larger for mild (d = 1.08, CI = 0.95-1.21) and severe (d = 1.09, CI = 0.91-1.26) services. For experience unqualified professionals produced smaller improvements for miscellaneous outcomes (d = 0.77, CI = 0.65-0.89) with no overlap; although superior improvements for anxiety outcomes (d = 1.12, CI = 0.86-1.39). Finally, for measurement tool, larger effect-sizes for anxiety outcomes was shown for the GAD-7 (d = 0.96, CI = 0.78-1.15) than the BAI (d = 0.71, CI = 0.54-0.88). For miscellaneous outcomes, the OQ-45 demonstrated smaller effect-sizes (d = 0.57, CI = 0.41-0.74) than the other commonly used measures (BSI, CORE-OM, SCL). For the meta-regression (i.e., continuous) variables, there was no significant omnibus models for depression outcomes or miscellaneous outcomes. Employment was the only significant model for the anxiety domain. For analysis*sessions, neither variable was significant when combined within a multi-variate model for any of the three outcome domains. These findings remained when allowing the variables to interact, with the interaction term also not significant. For loss to follow-up*sessions, the multi-variate model found sessions to not be significant for each domain. Continent was not significant for the anxiety or miscellaneous domain. Continent was significant for the depression domain but only the level of the UK. When allowing for interaction terms there was no significant moderator or interaction term for any of the domains. References "],["discussion.html", "Discussion Interpretation of Findings Limitations Implications for Research, Policy &amp; Practice Conclusion", " Discussion The aim of this review was to provide an up-to-date and systematic review of the literature for the effectiveness of psychological therapy in routine settings. 252 studies (k = 298) were identified, of which 223 (88.5%, k = 263) were eligible for the meta-analysis, producing the largest known synthesis of psychological therapy effectiveness studies conducted to date. The large number of included studies reflected the increased publication of practice-based evidence (71.48% since 2010). Consistent with prior psychotherapy effectiveness reviews, we found large pre-post effect sizes (d = 0.80 - 1.01) across multiple outcome domains (depression, anxiety, and miscellaneous outcomes). Continent was the only moderator significant for all domains, with UK and North American studies producing comparably larger effect-sizes. For depression outcomes, no other moderator was significant in explaining heterogeneity. Four subgroup moderators (modality, severity, experience, measurement tool) were significant for anxiety and miscellaneous outcomes. For treatment modality, cognitive-behavioral interventions produced larger effect-sizes for miscellaneous outcomes. For treatment severity, anxiety effect-sizes were larger in mild and university services, while miscellaneous outcomes were larger in mild and severe services. For experience, training professionals’ effect-sizes were larger (i.e., compared to qualified professionals) for anxiety outcomes, but smaller for miscellaneous outcomes. Finally, for measurement tool, sensitivity to change was higher for the GAD-7 (anxiety) and lower for the OQ-45 (global distress). Anxiety outpatient samples also outperformed inpatient samples. The only significant meta-regressive variable was for employment (i.e., larger rates linked to larger effect-sizes) within anxiety samples. Multivariate meta-regressive models (analysisXdosage, continentXdosage) produced null findings. Interpretation of Findings This review found that most individuals accessing psychological therapy are female, consistent with global epidemiological estimates of mental health gender prevalence (Seedat et al., 2009). The finding of large clinical improvements during psychotherapy and across outcomes was consistent with prior meta-analyses of psychotherapy effectiveness for depression outcomes (Hans &amp; Hiller, 2013; Wakefield et al., 2021), anxiety outcomes (Stewart &amp; Chambless, 2009; Wakefield et al., 2021), and nonspecific outcomes (Cahill et al., 2010). Pooled effect-sizes were smaller than that found for Cahill et al. (2010) (d = 1.29), although this may reflect differences in review focus (e.g., Cahill et al., 2010 included group treatments) or changing distribution of geographical representation (i.e., more studies from non-UK/North American countries). Large clinical improvements are also in fitting with countless meta-analyses of psychotherapy controlled trials (P. Cuijpers, Sijbrandij, et al., 2014; e.g., P. Cuijpers et al., 2008; Mayo-Wilson et al., 2014; Olatunji et al., 2014). It should be noted however that the sensitivity analysis (i.e., fixed effects model) demonstrated a notable drop in anxiety outcomes (from d 0.80 to 0.57), although this still represents important clinical improvements. The finding that the UK and North America produce larger effect-sizes was a novel finding. It is possible that there are continental differences in models of training, service structures, therapy provision and emphasis on evidence-based practice which underlie the observed differences in pooled effect-sizes between continents. This is consistent with UK and US clinical guidance recommending delivery of empirically supported treatments (APA, 2006; NICE, 2011). Despite differences, all continents demonstrated positive change for all outcomes (d = 0.59 - 1.10) supporting the universality hypothesis (i.e., that psychotherapy is assumed to work across cultures., Flückiger et al., 2018). Consistent with prior evidence Pim Cuijpers et al. (2020), psychotherapy produced strong clinical improvements for depression but with absence of evidence for significant between modality differences (Barth et al., 2013). The finding that counselling produced smaller effect-sizes for anxiety outcomes was not expected and may be an artefact of few included samples (k = 2). Perhaps more surprising was that cognitive-behavioural approaches fared no better than psychodynamic approaches, despite CBT being a front-line treatment within various mental healthcare systems (e.g., NICE, 2011). Cognitive-behavioural approaches produced superior effect sizes for miscellaneous outcomes however it was not clear (without further analysis) if this was related to superiority for global distress outcomes, specific diagnosis outcomes (e.g., PTSD, OCD) or a combination as this domain was not specific. Consistent with several prior meta-analytic reviews (e.g., P. Cuijpers, Turner, et al., 2014; Driessen et al., 2010; Furukawa et al., 2017) sample severity did not predict effectiveness of treatment for depression. For anxiety and miscellaneous outcomes, services categorised ‘mild’consistently produced larger outcomes. For anxiety, university samples were also comparable, while for miscellaneous outcomes inpatient only samples were comparable. In sum, effect-sizes for non-depression outcomes were consistently reduced for more severe community dwelling patients which provides support for increasing severity being associated with smaller improvements. What is less clear is the inconsistency for inpatient samples. For miscellaneous outcomes the inpatient setting produces comparable results (i.e., to outpatient) however for anxiety samples inpatient samples under performed. Classifying by type of service may have been an imprecise proxy for sample severity and therefore future research should explore severity as a continuous variable in routine settings. An unexpected finding was that trainee clinicians produced significantly larger effect-sizes for anxiety and smaller effect-sizes for miscellaneous outcomes. Prior research has largely failed to find a significant difference between qualified and unquailed clinicians (e.g., Boer et al., 2005; Buckley et al., 2006; Montgomery et al., 2010). A potential explanation is that clinicians in training are highly supervised and may therefore: (i) be less likely to ‘therapeutically drift’ (Waller &amp; Turner, 2016) from the identified therapeutic model, (ii) receive more up-to-date training on evidence-based approaches; and (iii) more readily engage in deliberate skills practice. It is not clear however why this would apply to anxiety conditions but not miscellaneous outcomes. The current study failed to find support for dosage, sample size, gender, type of analysis, ethnicity, stage of study development, age, or publication as moderators of effect size. Limitations Perhaps the most notable critique of this review is that it it based exclusively upon observational evidence (i.e., no control group or randomization). The absence of comparison conditions means that we are unable to rule out alternative explanations for observed effect-sizes such as placebo or natural recovery (Posternak &amp; Miller, 2001; Whiteford et al., 2012). A key design limitation surrounds statistical dependency. Efforts to avoid statistical dependency included: (i) taking one sample measure per domain, (ii) aggregating multiple unique study samples within a single domain, and (iii) extracting one measurement tool per study, per construct (i.e., preference system). These approaches have known limitations (Borenstein et al., 2021; Hoyt &amp; Del Re, 2018; Van den Noortgate et al., 2013). A more appropriate approach would have been to model dependency using a multi-level analysis (Van den Noortgate et al., 2013, 2015) and should be considered for replications. An additional limitation is that bias was not sufficiently assessed. It became apparent during the review stage that the RoB tool has significant limitations; that it is primarily auditing manuscript reporting detail and not necessarily risk of bias. In the absence of a sufficient assessment of RoB we could not determine the degree to which bias may have influenced results. Future reviews of effectiveness should strive to use the most appropriate RoB tool available (see Munder &amp; Barth, 2018). Due to resource constraints the systematic search, data extraction and RoB ratings were not performed in duplicate. For the subsample of full texts screened by two coders there was a strong, but not perfect agreement/ reliability (80%, \\(\\kappa\\) = 0.65). There is subsequently an almost guaranteed likelihood that several studies screened only once will have been incorrectly excluded. Future reviews should follow best practice guidelines of screening in duplicate (Polanin et al., 2019). Similarly, not extracting data or assessing RoB in duplicate is problematic due to risk of unreliable estimates of treatment effect and RoB (Armijo-Olivo et al., 2014). An additional limitation surrounds coding decisions of moderator variables. Therapy modality was coded from manuscript self-definition. The degree to which treatments actually resemble treatment code (or treatment intended) is not clear. It was also apparent during extraction that very few practice-based studies report fidelity/adherence checks. As this becomes more routinely reported opportunities for modelling differences based on fidelity/adherence will become available. The search strategy used in this review, although produced many results, is unlikely to have identified every available study. Search terms were based on prior reviews and omitted several terms that were found to produce an unmanageable number of hits (e.g., “effectiveness,” “evaluation”). Despite this we feel that the current reviews gives an adequate range and depth of effectiveness research with which to make tentative interpretations regarding the field of psychotherapy effectiveness research. A further caveat is the decision to focus exclusively on self-report measures of effectiveness. Meta-analytic evidence has demonstrated significant differences between self-report and clinician rated measures of clinical improvement (Pim Cuijpers et al., 2010). Future research is therefore needed to see if the pooled effect-sizes from this study are consistent with clinician rated measures of effectiveness in routine settings. Implications for Research, Policy &amp; Practice To provide further understanding around the effectiveness of routinely delivered therapy future research should: (a) include fidelity and competency measures to confirm whether treatments delivered resembled treatment intended; (b) routinely assess outcomes at follow-up to establish maintenance of gains; (c) provide greater representation of therapy outcomes from non-western countries/services; and (d) explore variability in outcome between clinicians. In terms of policy and practice, the following implications are considered. First, the need for development of reporting standards for practice-based evidence. The marked variation in how studies report details around the sample and intervention make comparisons and replication difficult. For example ethnicity rates were only reported for 127 samples (42.62%). This prevents accurate calculation of ethnicity rates across services/studies. Simply calculating the average rate of representation across those studies which do report statistics is not a valid approach as it is does not account for why studies omit ethnicity rates. Potential reasons include clinician/researcher oversight in reporting, or alternatively a marked lack of ethnic representation/access in these services/studies. There was also a lack of endeavor from studies to contextualize demographic utilization rates in terms of how representative they are of the populations/communities that they are intended to serve. Future practice-based studies of therapy effectiveness should routinely report all relevant rates of patient demographics and also quantify how proportionate they are of communities served. Second, this study found no evidence of differential outcome based on ethnicity, age, or marital status through meta-regression. This provides further support for the need to provide fair and equitable access of psycholotherapy across the dimensions of age, ethnicity and marital status as there is no evidence that they impede effectiveness. Third, routine recording of outcomes maintained at follow-up points should be enabled through necessary service commissioning of follow-up reviews/assessments. The body of evidence presented here concerns improvements made at the end of treatment. While follow-up was not included in this review, it was frequently apparent to reviewers that follow-up was rarely reported within studies. This information is necessary to determine the durability of improvements made during treatment. Fourth, in light of differential outcomes demonstrated between qualified and unqualified clinicians (e.g. unqualified producing greater outcomes for anxiety) a review of training needs may be required for clinicians at different levels of experience. Conclusion This review provides substantial support for the effectiveness of psychological therapy as delivered in routine settings across a range of outcomes. A key limitation of this review, and potentially the wider literature is the highly western-centric representation and reliance upon observational pre-post study designs. Nevertheless, for patients seeking help for psychological distress in routine services, there is growing evidence that interventions provided are clinically effective. The challenge for routine service delivery and associated effectiveness research is now to demonstrate the durability of this acute phase effect. References "],["tables.html", "Tables", " Tables Table 1: Inclusion and exclusion criteria used in the current review, shown using the PICOS framework (population, intervention, comparator, outcome, setting). criteria inclusion exclusion Population Sample exclusively aged 16 and above (lower end of sample age range is at least 16). Adolescent/child samples with a lower age limit below 16. Intervention Psychological intervention which includes individual face-to-face psycholgoical therapy (i.e. at least one session). Samples which indicate that any proportion of patients did not recieve at least one session of individual psychological therapy. Comparator Studies with pre and post intervention time points. Post intervention defined here as up to six months following treatment. Studies which do not report both pre and post intervention time points. (ii) Studies for which the post intervention time point is beyond six months following treatment termination. (iii) Treatment randomisation proceadures. Outcome Psychological treatment effectiveness using a validated self-report measurement tool. Service/settings which do not use a self-report measure of psychological effectiveness. Clinician reported measures were not included in this review. Setting Services for which a patient could expect to access psychological therapy (i.e. routine services). Service/settings that strongly do not appear naturalistic or reflect routine practice. Design Pre-post treatment designs. (ii) Studies which do not use a control condition. Studies which include a control group. (ii) Studies with N = &lt;6. (iii) Results not available/published in English. Table 2: Sumary coding sheet for extracting study information and categorising by level of moderator sub-group. These moderators form the categorical, sub-group variables for the current study. Moderator Level Description Setting Outpatient Sample of patients treated at an out-patient settings. Inpatient Sample of patients treated at either an (i) inpatient; (ii) day hospital; (iii) residential; or (iv) partial hospital setting. Completion Completer Sample of patients who all completed treatment. Includes Lost to Follow Up Sample of patients who used intention-to-treat principles. This is either (i) true ITT; or (ii) modified ITT (i.e. a minimum number of attended sessions). Sector University Clinics Sample of patients seen at (i) University training clinics; or (ii) University based out-patient clinics. Primary Sample of patients seen at a: (i) primary care; (ii) health; (iii) counselling/University counselling; (iv) voluntary ; (v) private [independent or group]; or (vi) employee assistential/occupational health service. Secondary Sample of patients seen at a: (i) secondary care; (ii) CMHTs /CMHC; (iii) tertiary/specialised psychotherapy; (iv) behavioural health/managed care ; or (v) Intensive out-patient setting. Inpatient Sample of patients treated at either an (i) inpatient; (ii) day hospital; (iii) residential; or (iv) partial hospital setting. Continent Continents Continent of study setting, consisting of either: (i) UK; (ii) mainland Europe; (iii) North America; (iv) Asia; (v) Australasia. Therapy Dynamic Therapy or counselling which follows a psychodynamic orientation. CBT Therapy or counselling which follows a cognitive and/or behavioural orientation. Counselling Counselling which is either (i) person-centered; or (ii) orientation not specified. Other Therapy or counselling which (i) has not been mentioned above, or (ii) is not specified/reported in the study manuscript. Trainee Unqualified Interventions exclusively made up of psychology trainees. Other All other samples/studies. Treatment Development Stage Preliminary Studies Methodologies including: (i) pilot or (ii) preliminary effectiveness studies. Routine Evaluations Methodologies including: (i) service evaluatons; (ii) benchmarking; (iii) routine outcome reporting; (iv) predictors of outcome/drop-out. Table 3: Proceadure for effect-size calculation. Steps Scenario Response Step 1 Manuscript reports all required information (N, M1, M2, SD1) for preferred d. Calculate preferred d. Step 2 Manuscript reports all information apart from Pearson’s r. E-mail corresponding authors to request r. Step 3 Manuscript does not report the mean or standard deviation but reports paired samples d. Use the reported d within the manuscript. Step 4 Manuscript does not report mean, standard deviation, or paired samples d however reports alternative metrics (e.g. median, range, standard error, ANOVA, regression Estimate the meand and standard deviation by converting available metrics. Step 5 All above steps attempted without success Study is not included in meta-analysis but is retained for narrative synthesis. Table 4: Full-text screening decision results for all studies Decision phase.1 phase.2 phase.3 Total Exclude 174 111 54 339 Include 130 79 43 252 No Access 21 7 0 28 Total 325 197 97 619 Note. Difinitions for different phases are as follows: Phase 1 = studies identified through the electonic database search. Phase 2 = studies identified through phase 1 reference lists and citation searching. Phase 3 = grey literature and studies provided by authors contacted during the study. Table 5: Summary statistics across the pooled sample and also by sector for varying variables. Level University Mild Moderate Severe Other Total N n 9195.000 158150.000 9515.000 22586.000 33694.000 233140.00000 samples 58.000 88.000 32.000 92.000 8.000 278.00000 mean 158.534 1797.159 297.344 245.500 4211.750 838.63309 median 93.500 121.000 61.000 63.000 93.000 81.50000 iqr 162.500 935.000 347.000 107.500 1999.750 224.50000 Females n 5350.000 95373.000 5797.000 14952.000 22801.000 144273.00000 Age samples 65.000 77.000 29.000 82.000 7.000 260.00000 mean 33.781 36.525 34.802 35.545 36.237 35.33012 min 20.500 19.000 24.300 21.520 24.520 19.00000 max 52.290 60.500 47.490 52.000 46.100 60.50000 Sessions samples 54.000 64.000 4.000 54.000 6.000 182.00000 mean 21.005 11.260 13.750 14.668 8.553 15.12771 min 2.150 4.000 9.000 1.000 8.000 1.00000 max 85.330 64.900 24.000 64.000 9.520 85.33000 median 14.770 8.175 11.000 11.150 8.150 13.00000 iqr 13.550 8.600 3.750 10.400 1.200 9.97500 Setting Mixed 0.000 0.000 0.000 0.000 5.000 5.00000 Outpatient 68.000 96.000 0.000 91.000 4.000 259.00000 Residential 0.000 0.000 33.000 1.000 0.000 34.00000 Continent Asia 4.000 1.000 0.000 0.000 1.000 6.00000 Australasia 5.000 0.000 0.000 5.000 0.000 10.00000 Europe 20.000 13.000 15.000 14.000 1.000 63.00000 N.America 38.000 32.000 10.000 39.000 4.000 123.00000 UK 1.000 50.000 8.000 34.000 3.000 96.00000 Completion ITT 48.000 48.000 16.000 53.000 4.000 169.00000 Completers 19.000 45.000 16.000 35.000 3.000 118.00000 NA 0.000 1.000 0.000 0.000 1.000 2.00000 Therapy CBT 43.000 41.000 14.000 49.000 5.000 152.00000 Counselling 0.000 22.000 0.000 3.000 0.000 25.00000 Dynamic 12.000 9.000 13.000 16.000 0.000 50.00000 Other 13.000 24.000 6.000 24.000 4.000 71.00000 hourglass Stage-1 4.000 6.000 7.000 16.000 1.000 34.00000 Stage-3 64.000 90.000 26.000 76.000 8.000 264.00000 Table 6: subgroup (categorical) moderator analyses for depression outcomes. Moderator Level k d ci Q I2 Random effects model for severity (Q = 0.79, p = 0.853) severity mild 34 1.03 1.22-0.85 9550225.84 100.0% university 30 0.98 1.16-0.79 43207.72 100.0% Secondary 57 0.98 1.11-0.86 80913.95 100.0% Residential 15 0.91 1.12-0.7 237284.01 100.0% Random effects model for analysis (Q = 2.93, p = 0.087) analysis include 81 0.93 1.03-0.84 9730935.19 100.0% Completers 59 1.08 1.22-0.94 221034.47 100.0% Random effects model for setting (Q = 0.45, p = 0.503) setting Outpatient 121 0.99 1.08-0.91 9660158.70 100.0% Residential 16 0.92 1.12-0.72 240002.33 100.0% Random effects model for continent (Q = 17.63, p = 0.001*) continent N.America 58 1.00 1.11-0.88 640493.04 100.0% UK 44 1.10 1.26-0.94 3564904.55 100.0% Europe 29 0.95 1.12-0.77 60424.34 100.0% Australasia 4 0.67 1.01-0.33 7087.67 100.0% Asia 5 0.59 0.8-0.37 91.78 96.0% Random effects model for therapy modality (Q = 1.16, p = 0.763) therapy modality psychodynamic 24 1.03 1.2-0.86 41984.43 100.0% Counselling 6 0.89 1.1-0.69 3471906.01 100.0% cognitive-behavioural 90 1.00 1.11-0.89 393181.50 100.0% Other 20 0.96 1.17-0.75 307948.08 100.0% Random effects model for treatment development stage (Q = 0.33, p = 0.566) Tretament stage routine evaluations 118 1.00 1.09-0.91 9955258.72 100.0% preliminary studies 22 0.95 1.12-0.78 546.66 96.0% Random effects model for experience (Q = 1.41, p = 0.235) experience qualified 121 1.01 1.1-0.92 9878905.77 100.0% trainees 19 0.90 1.06-0.74 76281.83 100.0% Random effects model for measurement tool (Q = 0, p = 0.956) measurement tool BDI 34 1.02 1.18-0.86 121013.68 100.0% PHQ-9 30 1.01 1.22-0.81 3495045.61 100.0% Random effects model for sample size (Q = 4.72, p = 0.094) sample size large 74 1.02 1.13-0.91 9949550.00 100.0% small 33 0.85 0.99-0.7 625.88 95.0% medium 33 1.08 1.26-0.89 5470.21 99.0% Note. Model Outputs in Bold are significant at either * p = &lt;.05. ** Bonferroni adjustment, p = &lt;.007 Table 7: subgroup (categorical) moderator analyses for anxiety outcomes. Moderator Level k d ci Q I2 Random effects model for severity (Q = 17.15, p = 0.001*) severity mild 22 0.99 1.2-0.79 334405.48 100.0% Secondary 24 0.63 0.76-0.5 30702.22 100.0% Residential 8 0.59 0.9-0.29 108223.63 100.0% university 29 1.01 1.2-0.83 32067.93 100.0% Random effects model for analysis (Q = 1.82, p = 0.178) analysis include 58 0.81 0.93-0.69 517063.05 100.0% Completers 26 0.96 1.14-0.77 92492.19 100.0% Random effects model for setting (Q = 4.34, p = 0.037*) setting Outpatient 75 0.89 0.99-0.78 440122.14 100.0% Residential 9 0.58 0.85-0.31 157933.03 100.0% Random effects model for continent (Q = 15.49, p = 0.004*) continent N.America 32 0.91 1.1-0.72 230641.72 100.0% UK 25 0.89 1.09-0.7 115765.33 100.0% Europe 20 0.79 0.93-0.65 27960.45 100.0% Australasia 4 0.61 1.01-0.21 3781.78 100.0% Asia 3 0.59 0.68-0.49 3.33 40.0% Random effects model for therapy modality (Q = 67.97, p = 0*) therapy modality psychodynamic 12 0.90 1.04-0.75 11879.61 100.0% Counselling 2 0.43 0.49-0.38 28.37 96.0% cognitive-behavioural 62 0.87 1-0.74 174811.70 100.0% Other 8 0.75 0.97-0.53 155956.84 100.0% Random effects model for treatment development stage (Q = 0.02, p = 0.885) Tretament stage routine evaluations 74 0.85 0.96-0.74 635244.53 100.0% preliminary studies 10 0.87 1.14-0.61 639.27 99.0% Random effects model for experience (Q = 5.77, p = 0.016*) experience qualified 66 0.78 0.88-0.68 502201.12 100.0% trainees 18 1.12 1.39-0.86 59913.29 100.0% Random effects model for measurement tool (Q = 3.92, p = 0.048*) measurement tool BAI 19 0.71 0.88-0.54 36173.30 100.0% GAD-7 19 0.96 1.15-0.78 241386.08 100.0% Random effects model for sample size (Q = 0.25, p = 0.885*) sample size large 45 0.84 0.95-0.72 635426.98 100.0% medium 13 0.93 1.3-0.57 2069.64 99.0% small 26 0.84 1.03-0.66 898.19 97.0% Note. Model Outputs in Bold are significant at either * p = &lt;.05. Table 8: subgroup (categorical) moderator analyses for miscellaneous outcomes. Moderator Level k d ci Q I2 Random effects model for severity (Q = 10.09, p = 0.018*) severity mild 61 1.08 1.21-0.95 39097618.60 100.0% Secondary 62 0.98 1.12-0.84 111313.98 100.0% Residential 27 1.09 1.26-0.91 66242.24 100.0% university 28 0.82 0.95-0.7 44711.91 100.0% Random effects model for analysis (Q = 1.8, p = 0.179) analysis include 95 0.98 1.09-0.87 12421993.52 100.0% Completers 89 1.08 1.18-0.97 10540486.30 100.0% Random effects model for setting (Q = 0.75, p = 0.386) setting Outpatient 153 1.00 1.08-0.92 104250384.75 100.0% Residential 28 1.08 1.25-0.91 67693.60 100.0% Random effects model for continent (Q = 13.53, p = 0.009*) continent UK 68 1.02 1.13-0.92 92810921.73 100.0% N.America 60 1.07 1.25-0.9 4606355.34 100.0% Europe 47 1.00 1.12-0.88 157855.31 100.0% Australasia 4 0.81 0.9-0.72 330.52 99.0% Asia 5 0.90 1.2-0.61 575.15 99.0% Random effects model for therapy modality (Q = 13.46, p = 0.004*) therapy modality cognitive-behavioural 83 1.18 1.32-1.05 178432.53 100.0% psychodynamic 36 0.93 1.07-0.79 49292.89 100.0% Counselling 19 0.90 1.06-0.75 318722.49 100.0% Other 46 0.87 0.98-0.76 103700450.06 100.0% Random effects model for treatment development stage (Q = 0.08, p = 0.781) Tretament stage preliminary studies 24 1.06 1.29-0.82 4742.50 100.0% routine evaluations 160 1.02 1.1-0.94 104380709.35 100.0% Random effects model for experience (Q = 16.86, p = 0*) experience qualified 158 1.07 1.16-0.99 104283036.81 100.0% trainees 26 0.77 0.89-0.65 71069.62 100.0% Random effects model for measurement tool (Q = 26.99, p = 0*) measurement tool BSI-GSI 26 0.87 1-0.73 9966.85 100.0% CORE-OM 35 1.04 1.18-0.9 72198841.45 100.0% OQ-45 13 0.57 0.74-0.41 1090596.15 100.0% SCL (Global) 22 1.05 1.23-0.87 15779.11 100.0% PCL 12 1.29 1.61-0.97 3642.32 100.0% Random effects model for sample size (Q = 1.03, p = 0.599*) sample size large 110 1.01 1.1-0.92 104379542.58 100.0% medium 38 1.11 1.3-0.92 4366.03 99.0% small 36 0.99 1.18-0.81 1001.45 97.0% Note. Model Outputs in Bold are significant at either * p = &lt;.05. Table 9: Meta-regression moderator variables (continuous) for depresison, anxiety and general outcome domains. Domain Moderator Mean (range) k B CI SE Q QMP R2 depression Year (of publication) 2012.16 (1988-2020) 140 0.00 0.01–0.02 0.01 0.24 0.62 0.00 mean age 36.25 (19-60.5) 126 0.00 0.01–0.01 0.01 0.11 0.74 0.00 Sessions (mean) 15.32 (1-46.5) 84 0.01 0.02-0 0.01 1.54 0.22 0.47 ethnicity (% minority) 0.23 (0-0.66) 62 -0.09 0.5–0.69 0.30 0.09 0.76 0.00 gender (% female) 0.67 (0-1) 132 0.00 0.4–0.39 0.20 0.00 0.99 0.00 employment (% in full-time 0.53 (0.05-1) 46 0.31 0.97–0.35 0.34 0.85 0.36 0.00 risk of bias (1-10) 5.62 (1-8) 140 0.04 0.09–0.01 0.03 2.03 0.15 0.67 anxiety Year (of publication) 2012.93 (1999-2020) 84 0.02 0.04-0 0.01 3.78 0.05 3.27 mean age 35.36 (19-60.5) 79 0.00 0.01–0.01 0.01 0.01 0.91 0.00 Sessions (mean) 16 (1-46.5) 52 0.00 0.01–0.01 0.01 0.03 0.85 0.00 ethnicity (% minority) 0.19 (0-0.59) 40 0.31 1.62–0.99 0.66 0.22 0.64 0.00 gender (% female) 0.67 (0.078-1) 79 -0.27 0.31–0.85 0.30 0.82 0.36 0.00 employment (% in full-time 0.6 (0.05-1) 29 0.95 1.55-0.35 0.31 9.64 0.00 24.18 risk of bias (1-10) 5.79 (1-8) 84 0.05 0.12–0.03 0.04 1.51 0.22 0.76 general Year (of publication) 2012.55 (2000-2020) 184 0.00 0.02–0.01 0.01 0.07 0.79 0.00 mean age 35.15 (21.8-52.5) 156 0.00 0.01–0.01 0.01 0.01 0.93 0.00 Sessions (mean) 15.5 (1-64.9) 108 -0.01 0–0.01 0.00 1.77 0.18 0.69 ethnicity (% minority) 0.26 (0-0.7) 69 -0.48 0.19–1.15 0.34 2.00 0.16 1.20 gender (% female) 0.67 (0-1) 173 -0.26 0.15–0.67 0.21 1.50 0.22 0.12 employment (% in full-time 0.53 (0-1) 60 -0.14 0.5–0.78 0.33 0.18 0.67 0.00 risk of bias (1-10) 5.6 (1-8) 184 0.05 0.1-0 0.03 3.78 0.05 1.59 Note. Model Outputs in Bold are significant at either * p = &lt;.05. "],["appendix.html", "Appendix Appendix A. Systematic search terms Appendix B. Preference system for outcome measures Appendix C. Systematic review screening tool Appendix D. Further information for extraction and coding process Appendix E. Quality appraisal tool Appendix F. Supplementary material link Appendix G. Systematic search exclusion reasons", " Appendix Appendix A. Systematic search terms Table 10: List of search terms and limiters for systematic database search Effectiveness Study Term Psychological Relevence Term Limiters ‘Practice based evidence’ Psycho* OR Therap [PsycInfo] English Language ‘Routine practice’ Psycho* [CINAHL and MEDLINE] Adult Sample Benchmarking Transportability Transferability Clinical* representat ’External valid* N0 findings Applicab* N0 findings Applicab* N0 intervention* ’Empiric* support’ N0 treatment ’Empiric* support’ N0 intervention ’Clinical* Effective*’ Dissem* N0 treatment* Dissem* N0 intervention* ‘Clinical Practice’ N0 intervention* ‘Clinical Practice’ N0 treatment* ’Service deliv’ N0 intervention ’Service deliv’ N0 treatment ’Clinical* effective’ N2 evaluat ’Service deliv’ N0 evaluat Transporting ‘Managed care setting’ Uncontrolled ‘Community clinic’ ‘Community mental health centre’ ‘Clinic setting’ ‘Service setting’ Appendix B. Preference system for outcome measures Because of the heterogeneity of outcome measures which could fit within the ‘general’ category the following hierarchy was used: (1) global measures of psychological distress (e.g. CORE-OM, SCL-90); (2) mono-symptomatic measures (e.g. Y-BOCS, EDE-Q). If a study used more than one measure at the same point in the hierarchy then we used the measure that had been most frequently employed in studies reviewed prior. Below is the final table of outcome measures used in the general category. Table 11: Frequency of outcome measures with at least three occurances Measure n domain BDI 78 depression PHQ-9 30 BSI (Depression) 8 SCL (Depression) 8 CESD-10 5 HADS (Depression) 4 DASS (Depression) 3 BAI 19 anxiety GAD-7 19 BSI (Anxiety) 8 HADS (Anxiety) 7 SCL (Anxiety) 6 PSWQ 5 DASS (Anxiety) 3 CORE-OM 35 general BSI-GSI 26 SCL (Global) 22 OQ-45 13 PCL 12 WSAS 7 Y-BOCS 7 EDEQ 6 BHM 5 GHQ 4 CORE-10 3 SF-36 3 Note. Abbreviations: Beck’s Depression Inventory (BDI); Patient Health Questionnaire-9 (PHQ-9); Brief Symptom Invetory (BSI); Symptom Checklist 90 Revised (SCL90R); Centre for Epidemiological Studies Depression Scale (CESD10); Depression Anxiety and Stress Scale (DASS); Hospial Anxiety &amp; Depression Scale (HADS) Short Form-36 (SF36); Beck’s Anxiety Inventory BAI); Generalised Anxeity Disorder-7 (GAD7); Penn-State Worry Questionnaire (PSWQ); CORE Outcome Measurement (CORE-OM); Outcome Questionnaire-45 (OQ45); PTSD Checklist (PCL); Work and Social Adjustment Scale (WSAS); Yale-Brown Obsessive Compulsive Scale (Y-BOCS); Eating Disorder Examination Questionnaire (EDEQ); Behavioural Health Measure (BHM); General Health Questionnaire (GHQ); Short Form-36 (SF36). Appendix C. Systematic review screening tool Table 12: List of search terms and limiters for systematic database search Criteria Theme Notes Is there a psychological intervention Psychological interventionists No exclusions should be made based on the interventionist. Is there a psychological intervention Multi-component or multi-disciplinary Multi-component or multi-disciplinary interventions which include individual psychology components should be included. Is there a psychological intervention Non-psychological interventions Interventions which use only medical, alternative (e.g. yoga, acupuncture), physical (exercise, physio) or occupational therapy should be excluded. Primary piece of quantitative research Review papers Meta-analyses or systematic reviews should be excluded. Primary piece of quantitative research Secondary Analysis Secondary analysis papers will be removed in favor of the initial/primary publication. Primary piece of quantitative research Overlapping Study Samples If studies have overlapping participants (but otherwise eligible) then the study with the larger sample size will be preferred unless there is a strong reason otherwise Is the sample exclusively adults Age If evidence of participants (any proportion) under the age of 16 then the study/sample should be excluded. Is the sample exclusively adults Adults Mention of “child” or “adolescent” participants is grounds for sample exclusion. Individual psychotherapy Mode of delivery If any proportion of the sample have only received group intervention (and therefore no individual psychotherapy) then exclude the study. Individual psychotherapy Couples and family therapy If any proportion of the sample have only received couples/family therapy then the sample should be excluded Individual psychotherapy Conjoint therapy If study/sample involves participants receiving multiple treatments then this is acceptable as long as one of the interventions is individual psychotherapy. Individual psychotherapy By proxy (carer/family) If any proportion of the sample have only received intervention by proxy (i.e. through family or carers only) then the study sample should be excluded. Effectiveness outcomes Effectiveness A measurement of treatment effectiveness if required. Studies which only use non-effectiveness based measures (e.g. process, satisfaction, cost-effectiveness, satisfaction, QoL) should be excluded. Effectiveness outcomes Pre-Post Pre-post comparisons are required. If samples only report the results of interventions that are not finished (e.g. 5 sessions of treatment) then this is acceptable. Effectiveness outcomes Follow-up If the post treatment observation is indicated by follow-up then this should not be more than 6 months Effectiveness outcomes Validated measures Study effectiveness measures should use a psychometrically validated questionnaire (or adapted from) Effectiveness outcomes Questionnaire studies Studies which seek to validate instruments in routine services are acceptable as long as pre-post data is available Effectiveness outcomes Self-report Only self-report measures are accepted. If any proportion of the sample only receive a clinician rates measure then the sample should be excluded. Face-to-face Format If any proportion of the sample have only received telephone or internet based treatment then the sample should be excluded Sample Size Sample Size Study samples should be at least 6 however analysed samples may be less than this. Not naturalistic Control group If the study uses any form of control group (e.g. TAU, WLC) then the study should be excluded. The only exception is if the control group is a historic naturalistic dataset. Not naturalistic Randomisation If any use of random assignment is used then the study should be excluded. Not naturalistic Recruited from routine settings If a study “recruits from” a routine setting, but the intervention is reported to take place in a non-routine treatment setting then the study should be excluded. Not naturalistic Use of internal controls No exclusion should be made based on financial incentive for participation; research/assessor involvement; competency/adherance measures; protocol based treatments; or qualification of interventionist Design Design No exclusions based on design other than that which related to prior criteria (i.e. exclusion of control groups or studies without pre-post data). Appendix D. Further information for extraction and coding process 0.0.1 Sample Characteristics There was high variability of demographic reporting for each study (e.g. gender, age, ethnicity etc.). For demographic information, the (i) mean age of each sample was extracted, and then (when reported) the number and percentage of: (ii) female, (iii), minority ethnic group, (iv) full-time employed, (v) and married patients. Each of these variables were summarised by averaging across mean averages for studies which reported this information. 0.0.2 Methodological Information For methodological information the type of completion analysis used was extracted. Samples were coded as either true ITT (everyone had an equal chance of inclusion), modified ITT, or completers. The stage of the hour-glass model was also recorded for each effectiveness study. Samples were rated as either stage-1 (pilot and preliminary effectiveness studies) or stage-3 (evaluation/benchmarking studies studies). The region (country and continent) was recorded; studies from the UK were separated from mainland Europe, due to the high volume of effectiveness research originating in the UK. 0.0.3 Service Information The type of service and associated sector were extracted for each study. As there were a large number of different sectors represented, a grouping system clustered similar sectors together. Services from primary care, health settings, counseling, and voluntary services were collated into a ‘primary’ sector category. Services delivering interventions for more specialist, complex or enduring presentations were grouped into a ‘secondary’ category. This included specialist/tertiary therapy services/clinics, community mental health teams/centers, and intensive out-patient services. University based services (either training clinics or counseling centers) were assigned to a ‘University clinics’ category. Finally, inpatient, day hospital and partial hospital services were grouped into a ‘inpatient’ category. Whether or not study interventionists consisted of clinicians in training was also recorded as a separate variable. We defined clinicians in training as staff training towards a professional psychology training course (i.e. clinical psychology interns/students, training psychiatrists or assistant psychologists). Staff who were not psychologists or qualified therapists, but who had a core profession (e.g. nurses, social workers) were not recognised as unqualified interventionists. 0.0.4 Treatment Information The treatment delivered was recorded for each study. Treatments were then assigned to a broad meta-therapy category, including: (i) cognitive and/or behavioural, (ii) dynamic/interpersonal, (iii) person-centered counseling (or counseling without a specified orientation), or (iv) other/non-specified. The average number of sessions was also recorded. For studies that reported the mean number of sessions then this was the metric extracted. For studies that alternatively used a time metric (days/weeks/months/years) then a uniform metric was applied (i.e. conversion to days). There was subsequently two possible dosage metrics, sessions of treatment and treatment days. If studies reported sample dosage, but with an alternative measure of central tendency (i.e. median) then this was converted to mean average. Appendix E. Quality appraisal tool Table 13: Adaprted version of ‘The Joanna Briggs Institute Critical Appraisal tools: Checklist for Case Series.’ Criteria Definition 1 Clear criteria for inclusion (if any form of inclusion criteria is provided and clearly stated). 2 Consecutive inclusion (need to be an explicit statement of being ‘consecutive’ or ‘all patients between the dates of.’ 3 Complete inclusion (fulfill previous criteria + true intention-to-treat analysis performed). 4 Clear reporting of demographics (2 out of the following: gender, age, ethnic, marital status, employment). 5 Clear reporting of treatment information (2 out of the following: details regarding the interventionist, type of treatment, number of sessions). 6 Post-outcome clearly reported (means and standard deviations are available). 7 Site/Clinic reporting details (i.e. brief statement about the nature of the host service/s). 8 Appropriate statistical analyses (measure of effect-size reported [e.g. cohen’s d, hedge’s g, reliable change])). Appendix F. Supplementary material link The supplementary material for the current review is available at: https://osf.io/p9sx5/?view_only=b906293276f54850824a1bcb86d47440 Included in the supplementary material is a complete bibliography, including all studies which featured in the qualitative synthesis and meta-analysis. Appendix G. Systematic search exclusion reasons Table 14: Frequency of exclusion reasons from the systematic search. ExclusionReason SecondaryReason n No effectiveness data Aggregated outcomes measure areas 1 Clinician rated measured 1 No effectiveness measure 21 No pre-post 22 No self-report 20 No validated measure 3 No individual psychotherapy By proxy 2 Family/couples 17 Group therapy 67 No primary data Book chapter 1 No psychology intervention 1 Overlap with other study 19 Review/meta 8 Secondary analysis 12 No psychotherapy No psychology intervention 11 Not adult population Not adult population 1 Not adult Population 4 Not face-to-face Format 2 Not naturalistic Control group 21 Randomisation 33 Recruited from routine settings 2 Stage II 4 Sample size Sample size 5 No English full-text No English full-text 1 No Psychotherapy No psychology intervention 1 Original Study Used Overlap with other study 5 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
