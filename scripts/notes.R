
# Assessment observers
Cuijpers et al 2010
This meta-analysis has made it clear that clinician-rated and self-report measures of improvement following psychotherapy for depression are not equivalent. Different symptoms may be more suitable for self-report or ratings by clinicians and in clinical trials it is probably best to include both.
Spielmans & Fluckiger 2018
For example, outcomes might be evaluated by different individuals such as patients, therapists, observers, and significant others using a variety of measures for these different perspectives (e.g., Horvath, Del Re, Flückiger, & Symonds, 2011)….
Including ratings from a variety of sources and perspectives is also recommended, as these can differ widely (Achenbach, McConaughy, & Howell, 1987; Spielmans & Gerwig, 2014).
Spielmans & Fluckiger 2018
Moreover, common “primary outcomes” such as symptom rating scales are somewhat arbitrary and likely have less empirical priority than the wording may suggest (e.g., Kazdin, 2006).
Thus, meta-analysts should typically report data across a variety of scales rather than assume one particular scale provides a clear picture of overall treatment outcome
The selection of treatment outcomes involves a variety of conceptual, methodological, and observa- tional decisions. For example, outcomes might be evaluated by different individuals such as patients, therapists, observers, and significant others using a variety of measures for these different perspectives (e.g., Horvath, Del Re, Flückiger, & Symonds, 2011). Moreover, common “primary outcomes” such as symptom rating scales are somewhat arbitrary and likely have less empirical priority than the wording may suggest (e.g., Kazdin, 2006). Thus, meta-analysts should typically report data across a variety of scales rather than assume one particular scale provides a clear picture of overall treatment outcome (i.e., across a broad mental health definition: http://www.who.int/features/factfiles/mental_health/ en/).

# type 1
MAP or Del re ?paper
When ESs are heterogeneous, determining what study characteristics that might account for the dispersion in the summary effect should be considered. However, it is important for meta-analysts to be selective in in their analyses and test only those study characteristics for which a strong theoretical case can be made, to avoid capitalizing on chance (Type I error) and identifying spurious moderator variables (Hunter & Schmidt, 2004).

Tipton & Pusteovsky paper
#"Concern with inflated Type I error was echoed in Hunter and Schmidt,36 who noted that most observed moderator analyses are likely spurious. They proposed that the best strategy is to focus on moderators defined in advance based on theory. This division of moderator analyses into confirmatory and exploratory analyses was also articulated by Mosteller and Chalmers, who argued”.

# Discussion

## Limitations
  # Moderators which have been missed.
      Spielmans & Fluckiger 2018
      Not coding items such as researcher alle- giance, whether comparison therapies are bona fide,
      comparative dosage, therapist training, therapist supervision, and other variables leaves open
      the possibility that apparent superiority of a therapy is merely a reflection of methodological
      biases operat- ing in favor of this treatment. Clearly, there might be further theory-driven,
      heretofore neglected mod- erators that should be examined in the future
      (such as e.g., socio-economic status).
  # Lack of duplicate coding
      Reviewer 3. Please elaborate on these points: Are these points threats to the validity of your findings?
        why? why not? Please highlight the issue with non-duplicate coding of effect sizes.

  # Search terms
      Search term used “routine practice” as a required key word.  Authors might well have used other key words, such as “naturalistic” or “clinical practice.”  As a result, there were oft cited studies missing (e.g., Wampold & Brown, 2005).
      Response: We recognise that our search terms are unlikely to capture all eligible studies. We have emphasised this more now in the limitations sections.
  # full text screening agreement
      Full text screening: Very often this is done and duplicate, while in your study only 10% of full texts received a second evaluation. 6 disagreements out of 30 second evaluations suggest there might have been errors across the 90% of other full texts. Briefly inform on whether it is likely that an important study might have been missed.
      Response: We have now discussed within limitations.
  # Extraction
      7. Data extraction: I think it is problematic to not extract in duplicate, especially for the effect sizes. The kappa you provide is good, however, it is not specific for the type of variable extracted and with effect sizes even few errors are problematic. I guess the minimum here would be to provide appropriate interrater agreement for effect sizes separately and to discuss the limitation of non-duplicate extraction in the discussion. The other option would be to extract effect sizes in duplicate.
      Response: We have now provided irr for effect-size data specifically (kappa = 1.00). We have discussed the limitation of not performing in duplicate within the discussion.
  # multi-variate
      8. Multivariate Moderator analysis: It is not entirely clear why the different models were chosen, why not all variables were entered simultaneously, and whether this was pre-registered. Please elaborate. I find you have so many interesting moderators. Why not do more exploratory simultaneous analyses? I find the passage in the Results on this hard to understand. Can this be easier to follow?
        Response: Thank you for these comments. We have made the moderator sections of the results section more succinct and straightforward. We have also provided more clarity on the statistical models used.
      We have now reported our rationale for our model and the reason for not entering all models at once however we have also reflected on this as a potential limitation of the study.








## other
Therapist training and supervision are regarded as important aspects in psychotherapy
(Wilson, Davies, & Weatherhead, 2016).

#
Spielmans & Fluckiger 2018
Study results can be influenced by sample character- istics that are impacted by inclusion and exclusion criteria (see Swift & Wampold in this issue). General- izability across sample characteristics is a vital research question in many research contexts (e.g., across countries, cultures, and languages). Moreover, the study enrollment process often results in samples that are not fully representative of the overall popu- lation of interest. For example, the inclusion or exclu- sion of participants with substance-use disorder might impact not only the specific mental disorder but also the psychosocial environment, including the participants’ decision to seek a psychotherapy involved in a trial (Chow, Jaffee, & Snowden, 2003).

#
Spielmans & Fluckiger 2018
individual study effects are often distributed quite widely (more widely than in a normal distribution) indicating diversity as a common phenomenon, in which case the aggregate effect may not describe the individual effects particularly well.
Further, casting a broad net to include multi- concept, multi-method assessments of social/occu- pational/academic functioning and quality of life pro- vides a more comprehensive estimate of real-world benefits (e.g., Eid, Geiser, & Nussbaeck, 2009).
Most comparative psychotherapy outcome studies suffer from more than one confound (Budge et al., 2013; Spielmans et al., 2010, 2013). It is useful to analyze moderators on an individual level, but their combination likely has a cumulative impact. Meta- analysts have typically not accounted for multiple confounds simultaneously, likely because statistical power is reduced as more complex combinations of moderators are examined. Often incomplete report- ing of potential relevant confounds in primary studies further reduces the ability to detect their impact. Meta-analysts are nonetheless encouraged to examine how various combinations of moderators may influence treatment effects (e.g., Weisz et al., 2013). This is challenging given that many studies do not adequately report on potential

# Nordmo 2020
“As this study is a cohort study without a control group, we cannot ascertain a causal link between
patient improvement and the psychotherapy received. Due to ethical concerns (47) and
practical challenges (48), few studies focus on untreated psychiatric populations.
The lack of studies on untreated psychiatric populations makes it difficult to compare our treatment
sample with a hypothetical no-treatment control. The studies that do exist are mainly on patients
with a mild to moderate mood and/or an anxiety disorders (49, 50).
These studies suggest that spontaneous recovery for anxiety and mood disorders is common,
but estimates vary greatly between studies. Spontaneous recovery is documented to be rarer for
patients diagnosed with a comorbid personality disorder (51–54) than for patients without.
There is a lack of data for recovery rates of severely ill populations that are not in treatment
as these individuals are typically high-treatment utilizers (55). We would argue that the samples
presented in the spontaneous recovery literature is of milder psychopathology compared to our sample,
where 54% fulfilled the criteria for one or more personality disorders at admission.
The robust positive changes seen in our sample seems greater than what one might expect from the rate
of natural recovery found in each disorder. We also believe that the observation that our sample
maintained the therapeutic gains during the follow-up is indicative that positive changes should be
ascribed the therapy received. This lasting change is contrasted to the chronicity reported pretreatment.
Although randomization to a control condition can open the road to causal analyses,
we believe that that this is precarious for research on long-term treatments for severely ill patients
that seek to compare routine care and spontaneous recovery. In such a scenario, the control condition
would have to limit or omit routine care for several years forcefully. This dynamic is also apparent
in the controversy surrounding evidence-based therapies (56).”





