---
editor_options: 
  markdown: 
    wrap: sentence
---
\newpage

# Discussion {.unnumbered}

The aim of this review was to provide an up-to-date and systematic review of the literature for the effectiveness of psychological therapy in routine settings. `r dat.mod %>% filter(StudySampleN == 1) %>% nrow()` studies (*k* = `r dat.mod %>% nrow()`) were identified, of which 
`r dat.mod %>% filter(StudySampleN == 1 & For.Meta == "Yes") %>% nrow()`
(88.5%, *k* = `r dat.mod %>% filter(For.Meta == "Yes") %>% nrow()`) were eligible for the meta-analysis, producing the largest known synthesis of psychological therapy effectiveness studies conducted to date. The large number of included studies reflected the increased publication of practice-based evidence (`r round(dat.mod %>% filter(Year >= 2010) %>% nrow()/dat.mod %>% nrow()*100, 2)`% since 2010). Consistent with prior psychotherapy effectiveness reviews, we found large pre-post effect sizes (*d* = 0.80 - 1.01) across multiple outcome domains (depression, anxiety, and miscellaneous outcomes). Continent was the only moderator significant for all domains, with UK and North American studies producing comparably larger effect-sizes.

For depression outcomes, no other moderator was significant in explaining heterogeneity. Four subgroup moderators (modality, severity, experience, measurement tool) were significant for anxiety and miscellaneous outcomes. For treatment modality, cognitive-behavioral interventions produced larger effect-sizes for miscellaneous outcomes. For treatment severity, anxiety effect-sizes were larger in mild and university services, while miscellaneous outcomes were larger in mild and severe services. For experience, training professionals’ effect-sizes were larger (i.e., compared to qualified professionals) for anxiety outcomes, but smaller for miscellaneous outcomes. Finally, for measurement tool, sensitivity to change was higher for the GAD-7 (anxiety) and lower for the OQ-45 (global distress). Anxiety outpatient samples also outperformed inpatient samples. The only significant meta-regressive variable was for employment (i.e., larger rates linked to larger effect-sizes) within anxiety samples. Multivariate meta-regressive models (analysisXdosage, continentXdosage) produced null findings.

## Interpretation of Findings {-}

This review found that most individuals accessing psychological therapy are female, consistent with global epidemiological estimates of mental health gender prevalence (Seedat et al., 2009). The finding of large clinical improvements during psychotherapy and across outcomes was consistent with prior meta-analyses of psychotherapy effectiveness for depression outcomes [@Hans2013; @Wakefield2021], anxiety outcomes [@Stewart2009a; @Wakefield2021], and nonspecific outcomes [@Cahill2010]. Pooled effect-sizes were smaller than that found for @Cahill2010 (*d* = 1.29), although this may reflect differences in review focus (e.g., Cahill et al., 2010 included group treatments) or changing distribution of geographical representation (i.e., more studies from non-UK/North American countries). Large clinical improvements are also in fitting with countless meta-analyses of psychotherapy controlled trials [e.g., @Cuijpers2008; @Cuijpers2014; @Mayo-Wilson2014; @Olatunji2014]. It should be noted however that the sensitivity analysis (i.e., fixed effects model) demonstrated a notable drop in anxiety outcomes (from *d* 0.80 to 0.57), although this still represents important clinical improvements.

The finding that the UK and North America produce larger effect-sizes was a novel finding. It is possible that there are continental differences in models of training, service structures, therapy provision and emphasis on evidence-based practice which underlie the observed differences in pooled effect-sizes between continents. This is consistent with UK and US clinical guidance recommending delivery of empirically supported treatments [@APA2006; @NICE2011]. Despite differences, all continents demonstrated positive change for all outcomes (*d* = 0.59 - 1.10) supporting the universality hypothesis [i.e., that psychotherapy is assumed to work across cultures., @Fluckiger2018].

Consistent with prior evidence [e.g., @Barth2013a @Cuijpers2020], psychotherapy produced strong clinical improvements for depression but with absence of evidence for significant between modality differences [@Barth2013a]. The finding that counselling produced smaller effect-sizes for anxiety outcomes was not expected and may be an artefact of few included samples (*k* = 2). Perhaps more surprising was that cognitive-behavioural approaches fared no better than psychodynamic approaches, despite CBT being a front-line treatment within various mental healthcare systems [e.g., @NICE2011]. Cognitive-behavioural approaches produced superior effect sizes for miscellaneous outcomes however it was not clear (without further analysis) if this was related to superiority for global distress outcomes, specific diagnosis outcomes (e.g., PTSD, OCD) or a combination as this domain was not specific.

Consistent with several prior meta-analytic reviews [e.g., @Cuijpers2014a; @Driessen2010; @Furukawa2017] sample severity did not predict effectiveness of treatment for depression. For anxiety and miscellaneous outcomes, services categorised ‘mild’consistently produced larger outcomes.  For anxiety, university samples were also comparable, while for miscellaneous outcomes inpatient only samples were comparable. In sum, effect-sizes for non-depression outcomes were consistently reduced for more severe community dwelling patients which provides support for increasing severity being associated with smaller improvements. What is less clear is the inconsistency for inpatient samples. For miscellaneous outcomes the inpatient setting produces comparable results (i.e., to outpatient) however for anxiety samples inpatient samples under performed. Classifying by type of service may have been an imprecise proxy for sample severity and therefore future research should explore severity as a continuous variable in routine settings.

An unexpected finding was that trainee clinicians produced significantly larger effect-sizes for anxiety and smaller effect-sizes for miscellaneous outcomes. Prior research has largely failed to find a significant difference between qualified and unquailed clinicians [e.g.,@Boer2005; @Buckley2006; @Montgomery2010]. A potential explanation is that clinicians in training are highly supervised and may therefore: (i) be less likely to ‘therapeutically drift’ [@Waller2016] from the identified therapeutic model, (ii) receive more up-to-date training on evidence-based approaches; and (iii) more readily engage in deliberate skills practice. It is not clear however why this would apply to anxiety conditions but not miscellaneous outcomes.
The current study failed to find support for dosage, sample size, gender, type of analysis, ethnicity, stage of study development, age, or publication as moderators of effect size. 

## Limitations {-}

Perhaps the most notable critique of this review is that it it based exclusively upon observational evidence (i.e., no control group or randomization). The absence of comparison conditions means that we are unable to rule out alternative explanations for observed effect-sizes such as placebo or natural recovery [@Posternak2001; @Whiteford2012].

A key design limitation surrounds statistical dependency. Efforts to avoid statistical dependency included: (i) taking one sample measure per domain, (ii) aggregating multiple unique study samples within a single domain, and (iii) extracting one measurement tool per study, per construct (i.e., preference system). These approaches have known limitations [@VandenNoortgate2013a; @Hoyt2018; @Borenstein2021]. A more appropriate approach would have been to model dependency using a multi-level analysis [@VandenNoortgate2013a; @VandenNoortgate2015] and should be considered for replications.

An additional limitation is that bias was not sufficiently assessed. It became apparent during the review stage that the RoB tool has significant limitations; that it is primarily auditing manuscript reporting detail and not necessarily risk of bias. In the absence of a sufficient assessment of RoB we could not determine the degree to which bias may have influenced results. Future reviews of effectiveness should strive to use the most appropriate RoB tool available [see @Munder2018].

Due to resource constraints the systematic search, data extraction and RoB ratings were not performed in duplicate. For the subsample of full texts screened by two coders there was a strong, but not perfect agreement/ reliability (80%, $\kappa$ = 0.65). There is subsequently an almost guaranteed likelihood that several studies screened only once will have been incorrectly excluded. Future reviews should follow best practice guidelines of screening in duplicate [@Polanin2019]. Similarly, not extracting data or assessing RoB in duplicate is problematic due to risk of unreliable estimates of treatment effect and RoB [@Armijo-Olivo2014].
An additional limitation surrounds coding decisions of moderator variables. Therapy modality was coded from manuscript self-definition. The degree to which treatments actually resemble treatment code (or treatment intended) is not clear. It was also apparent during extraction that very few practice-based studies report fidelity/adherence checks. As this becomes more routinely reported opportunities for modelling differences based on fidelity/adherence will become available.

The search strategy used in this review, although produced many results, is unlikely to have identified every available study. Search terms were based on prior reviews and omitted several terms that were found to produce an unmanageable number of hits (e.g., “effectiveness”, “evaluation”). Despite this we feel that the current reviews gives an adequate range and depth of effectiveness research with which to make tentative interpretations regarding the field of psychotherapy effectiveness research.

A further caveat is the decision to focus exclusively on self-report measures of effectiveness. Meta-analytic evidence has demonstrated significant differences between self-report and clinician rated measures of clinical improvement [@Cuijpers2010a]. Future research is therefore needed to see if the pooled effect-sizes from this study are consistent with clinician rated measures of effectiveness in routine settings.

```{r EthnicityReporting, include = FALSE}
EthnicityNRates <- dat.mod %>% select(Minority.perc) %>% drop_na() %>% nrow()
```

## Implications for Research, Policy & Practice {.unnumbered}

To provide further understanding around the effectiveness of routinely delivered therapy future research should: (a) include fidelity and competency measures to confirm whether treatments delivered resembled treatment intended; (b) routinely assess outcomes at follow-up to establish maintenance of gains; (c) provide greater representation of therapy outcomes from non-western countries/services; and (d) explore variability in outcome between clinicians.

In terms of policy and practice, the following implications are considered. First, the need for development of reporting standards for practice-based evidence. The marked variation in how studies report details around the sample and intervention make comparisons and replication difficult. For example ethnicity rates were only reported for  `r EthnicityNRates` samples (`r round(EthnicityNRates/(dat.mod %>% nrow())*100,2)`%). This prevents accurate calculation of ethnicity rates across services/studies. Simply calculating the average rate of representation across those studies which do report statistics is not a valid approach as it is does not account for why studies omit ethnicity rates. Potential reasons include clinician/researcher oversight in reporting, or alternatively a marked lack of ethnic representation/access in these services/studies. There was also a lack of endeavor from studies to contextualize demographic utilization rates in terms of how representative they are of the populations/communities that they are intended to serve. Future practice-based studies of therapy effectiveness should routinely report all relevant rates of patient demographics and also quantify how proportionate they are of communities served.

Second, this study found no evidence of differential outcome based on ethnicity, age, or marital status through meta-regression. This provides further support for the need to provide fair and equitable access of psycholotherapy across the dimensions of age, ethnicity and marital status as there is no evidence that they impede effectiveness.

Third, routine recording of outcomes maintained at follow-up points should be enabled through necessary service commissioning of follow-up reviews/assessments. The body of evidence presented here concerns improvements made at the end of treatment. While follow-up was not included in this review, it was frequently apparent to reviewers that follow-up was rarely reported within studies. This information is necessary to determine the durability of improvements made during treatment.

Fourth, in light of differential outcomes demonstrated between qualified and unqualified clinicians (e.g. unqualified producing greater outcomes for anxiety) a review of training needs may be required for clinicians at different levels of experience.

## Conclusion {-}
This review provides substantial support for the effectiveness of psychological therapy as delivered in routine settings across a range of outcomes. A key limitation of this review, and potentially the wider literature is the highly western-centric representation and reliance upon observational pre-post study designs. Nevertheless, for patients seeking help for psychological distress in routine services, there is growing evidence that interventions provided are clinically effective. The challenge for routine service delivery and associated effectiveness research is now to demonstrate the durability of this acute phase effect.

